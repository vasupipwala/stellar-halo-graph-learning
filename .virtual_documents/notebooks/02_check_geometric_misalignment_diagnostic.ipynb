import numpy as np
import astropy.units as u
import matplotlib.pyplot as plt
import pickle
import datetime
import platform
import gala
import astropy
from astropy.coordinates import CartesianRepresentation, CartesianDifferential
from sklearn.decomposition import PCA
from scipy.ndimage import uniform_filter1d
from sklearn.metrics import r2_score
import pandas as pd
from scipy.stats import f_oneway

from matplotlib.colors import Normalize
from matplotlib.cm import ScalarMappable
from mpl_toolkits.axes_grid1 import make_axes_locatable
from matplotlib.lines import Line2D
import seaborn as sns

from gala.units import galactic
from gala.potential import Hamiltonian
from gala.potential import LogarithmicPotential
from gala.dynamics import PhaseSpacePosition
from gala.dynamics.mockstream import (
    MockStreamGenerator,
    FardalStreamDF
)
from gala.integrate import LeapfrogIntegrator


from tqdm.notebook import tqdm
import time
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.animation import FuncAnimation
from matplotlib.animation import FFMpegWriter


with open("../data/gc_stream_ensemble.pkl", "rb") as f:
    data = pickle.load(f)

streams = data["streams"]


def extract_stream_snapshot(stream_tuple, t_array, time_index=0):

    mock = stream_tuple[0]
    nt = len(t_array)

    total_points = mock.pos.x.shape[0]

    if total_points % nt != 0:
        raise ValueError(
            "Total points not divisible by number of time steps."
        )

    npart = total_points // nt

    # Reshape to (nt, npart)
    x_all = mock.pos.x.reshape(nt, npart)
    y_all = mock.pos.y.reshape(nt, npart)
    z_all = mock.pos.z.reshape(nt, npart)

    vx_all = mock.vel.d_x.reshape(nt, npart)
    vy_all = mock.vel.d_y.reshape(nt, npart)
    vz_all = mock.vel.d_z.reshape(nt, npart)

    # IMPORTANT: Reverse time axis if needed
    # Because stream storage is often reversed relative to t_array
    x_all = x_all[::-1]
    y_all = y_all[::-1]
    z_all = z_all[::-1]

    vx_all = vx_all[::-1]
    vy_all = vy_all[::-1]
    vz_all = vz_all[::-1]

    # Extract requested epoch
    x = x_all[time_index]
    y = y_all[time_index]
    z = z_all[time_index]

    vx = vx_all[time_index]
    vy = vy_all[time_index]
    vz = vz_all[time_index]

    pos = CartesianRepresentation(x, y, z)
    vel = CartesianDifferential(vx, vy, vz)

    pos = pos.with_differentials(vel)

    return PhaseSpacePosition(pos)


def make_galactic_hamiltonian(q=1.0):
    pot = LogarithmicPotential(
        v_c=220 * u.km/u.s,
        r_h=12 * u.kpc,
        q1=1.0,
        q2=1.0,
        q3=q,
        units=galactic
    )
    return Hamiltonian(pot)


def compute_theta_curve(stream_orbits, orbit):

    nt = stream_orbits.pos.x.shape[0]
    theta = np.zeros(nt)

    for i in range(nt):

        # --- 3D stream positions ---
        xyz = np.vstack([
            stream_orbits.pos.x[i].value,
            stream_orbits.pos.y[i].value,
            stream_orbits.pos.z[i].value
        ]).T

        # --- PCA principal axis ---
        pca = PCA(n_components=1)
        pca.fit(xyz)

        axis = pca.components_[0]
        axis = axis / np.linalg.norm(axis)

        # --- Progenitor velocity direction ---
        v = np.array([
            orbit.vel.d_x[i].value,
            orbit.vel.d_y[i].value,
            orbit.vel.d_z[i].value
        ])

        vhat = v / np.linalg.norm(v)

        # --- FIX: use absolute value to remove sign degeneracy ---
        cosang = np.clip(np.abs(np.dot(axis, vhat)), 0, 1)

        theta[i] = np.degrees(np.arccos(cosang))

    return theta


def signal_to_noise(df, metric, halo1, halo2):

    """
     Cohenâ€™s d (effect size)
    """

    group1 = df[df.halo == halo1][metric]
    group2 = df[df.halo == halo2][metric]

    n1, n2 = len(group1), len(group2)
    mu1, mu2 = group1.mean(), group2.mean()
    sigma1, sigma2 = group1.std(), group2.std()

    sigma_pooled = np.sqrt(
        ((n1 - 1)*sigma1**2 + (n2 - 1)*sigma2**2)
        / (n1 + n2 - 2)
    )

    S = abs(mu1 - mu2) / sigma_pooled

    return S


def variance_ratio(df, metric):

    # Total mean
    grand_mean = df[metric].mean()

    # Between-halo variance
    group_means = df.groupby("halo")[metric].mean()
    n_per_group = df.groupby("halo")[metric].count()

    between_var = 0
    for halo in group_means.index:
        between_var += n_per_group[halo] * (group_means[halo] - grand_mean)**2

    between_var /= (len(group_means) - 1)

    # Within-halo variance
    within_var = 0
    for halo in group_means.index:
        group = df[df.halo == halo][metric]
        within_var += ((group - group.mean())**2).sum()

    within_var /= (len(df) - len(group_means))

    R = between_var / within_var

    return R





for i, s in enumerate(streams):

    print(f"\nProcessing stream {i} ({s['halo']})")
    # ----------------------------------
    # 2. Extract present-day stream snapshot
    # ----------------------------------
    stream_snapshot = extract_stream_snapshot(
        s["stream"],
        s["t"],
        time_index=0     # <-- FIXED
    )

    assert np.allclose(stream_snapshot.pos.xyz.mean(axis=1),
                   s["orbit"][0].pos.xyz,
                   atol=0.1 * u.kpc)





results = []


for i, s in enumerate(streams):

    print(f"\nProcessing stream {i} ({s['halo']})")

    # ----------------------------------
    # 1. Build Hamiltonian
    # ----------------------------------
    H = make_galactic_hamiltonian(q=s["q"])

    # ----------------------------------
    # 2. Extract present-day snapshot
    # ----------------------------------
    stream_snapshot = extract_stream_snapshot(
        s["stream"],
        s["t"],
        time_index=0
    )

    n_particles = stream_snapshot.pos.x.shape[0]
    print(f"Particles: {n_particles}")

    # ----------------------------------
    # 3. Time grid (forward evolution)
    # ----------------------------------
    t_anim = np.arange(-4000, 0, 20) * u.Myr
    t_Gyr = t_anim.to_value(u.Gyr)

    # ----------------------------------
    # 4. Integrate stream + orbit
    # ----------------------------------
    stream_orbits = H.integrate_orbit(
        stream_snapshot,
        t=t_anim,
        Integrator=LeapfrogIntegrator
    )

    prog_present = s["orbit"][0]

    orbit = H.integrate_orbit(
        prog_present,
        t=t_anim,
        Integrator=LeapfrogIntegrator
    )

    # ----------------------------------
    # 5. Compute 3D misalignment curve
    # ----------------------------------
    theta_curve = compute_theta_curve(stream_orbits, orbit)

    # ----------------------------------
    # 6. Robust scalar metrics
    # ----------------------------------

    # Late-time mean (-2 to 0 Gyr)
    late_mask = t_Gyr >= -2.0
    theta_late_mean = np.mean(theta_curve[late_mask])

    # Early-time growth (-4 to -3 Gyr)
    early_mask = (t_Gyr >= -4.0) & (t_Gyr <= -3.0)
    theta_early_growth = (
        np.mean(theta_curve[early_mask])
    )

    # Time-integrated misalignment
    theta_auc = np.trapz(theta_curve, t_Gyr)

    # ----------------------------------
    # 7. Store results
    # ----------------------------------
    results.append({
        "halo": s["halo"],
        "q": s["q"],
        "mass": s["mass"].value,
        "time_Gyr": t_Gyr,
        "theta_deg": theta_curve,
        "theta_mean": float(np.mean(theta_curve)),
        "theta_std": float(np.std(theta_curve)),
        "theta_max": float(np.max(theta_curve)),
        "theta_auc": float(theta_auc),
        "theta_late_mean": float(theta_late_mean),
        "theta_early_mean": float(theta_early_growth),
        "n_particles": stream_orbits.pos.x.shape[1],
    })

    print(f"theta_mean: {np.mean(theta_curve):.3f}")
    print(f"theta_late_mean: {theta_late_mean:.3f}")
    print(f"theta_auc: {theta_auc:.3f}")





df = pd.DataFrame(results)

print(df.head())


print(df.groupby("halo").size())


df


metrics = [
    "theta_mean",
    "theta_late_mean",
    "theta_early_mean",
    "theta_max",
    "theta_auc"
]

fig, axes = plt.subplots(1, len(metrics), figsize=(20, 5))

for ax, metric in zip(axes, metrics):
    sns.boxplot(
        data=df,
        x="halo",
        y=metric,
        ax=ax
    )
    sns.stripplot(
        data=df,
        x="halo",
        y=metric,
        ax=ax,
        color="black",
        size=5,
        alpha=0.6
    )
    ax.set_title(metric)

plt.tight_layout()
# plt.savefig('../figures/box_plot_metric_comparison', dpi=140)
# plt.close()


fig, axes = plt.subplots(1, len(metrics), figsize=(20, 5))

for ax, metric in zip(axes, metrics):
    sns.violinplot(
        data=df,
        x="halo",
        y=metric,
        ax=ax,
        inner="point"
    )
    ax.set_title(metric)

plt.tight_layout()
# plt.savefig('../figures/violin_plot_metric_comparison', dpi=140)
# plt.close()


metrics = ["theta_mean", "theta_late_mean", "theta_auc"]

fig, axes = plt.subplots(1, len(metrics), figsize=(15,5))

for ax, metric in zip(axes, metrics):

    for halo in df.halo.unique():

        vals = df[df.halo==halo][metric].values
        mean = vals.mean()
        std = vals.std()

        ax.scatter(
            [halo]*len(vals),
            vals,
            s=60
        )

        ax.errorbar(
            halo,
            mean,
            yerr=std,
            fmt="o",
            capsize=5,
            linewidth=2
        )

    ax.set_title(metric)

plt.tight_layout()
# plt.savefig('../figures/dot_plot_metric_comparison', dpi=140)
# plt.close()


# Signal-to-Noise Metric

metrics = ["theta_mean", "theta_late_mean", "theta_auc",] #"theta_early_mean",
    #"theta_max",]

for metric in metrics:
    
    S_sph_obl = signal_to_noise(df, metric, "spherical", "oblate")
    S_sph_pro = signal_to_noise(df, metric, "spherical", "prolate")
    S_obl_pro = signal_to_noise(df, metric, "oblate", "prolate")
    
    print(f'{metric} : ')
    print("S (spherical vs oblate):", S_sph_obl)
    print("S (spherical vs prolate):", S_sph_pro)
    print("S (oblate vs prolate):", S_obl_pro)
    print('\n')


# Halo Discrimination Test (ANOVA)

summary_stats = []
metrics = ["theta_mean", "theta_late_mean", "theta_auc",]

for metric in metrics:

    f_stat, p_value = f_oneway(
        df[df.halo=="spherical"][metric],
        df[df.halo=="oblate"][metric],
        df[df.halo=="prolate"][metric]
    )

    summary_stats.append({
        "metric": metric,
        "F": f_stat,
        "p_value": p_value
    })

summary_df = pd.DataFrame(summary_stats)
print(summary_df)


# Variance Ratio

for metric in ["theta_mean", "theta_late_mean", "theta_auc"]:
    R = variance_ratio(df, metric)
    print(metric, "variance ratio R =", R)


# Mean Misalignment Curves Stacked

# Convert results list to structured format
halo_curves = {}

for halo in df.halo.unique():

    halo_entries = [r for r in results if r["halo"] == halo]

    time = halo_entries[0]["time_Gyr"]

    theta_stack = np.array([r["theta_deg"] for r in halo_entries])

    halo_curves[halo] = {
        "time": time,
        "mean": theta_stack.mean(axis=0),
        "std": theta_stack.std(axis=0)
    }

plt.figure(figsize=(8,6))

for halo in halo_curves:

    t = halo_curves[halo]["time"]
    mean = halo_curves[halo]["mean"]
    std = halo_curves[halo]["std"]

    plt.plot(t, mean, label=halo)
    plt.fill_between(t, mean-std, mean+std, alpha=0.2)

plt.xlabel("Time [Gyr]")
plt.ylabel("Misalignment angle [deg]")
plt.legend()
plt.title("Mean Misalignment Curves by Halo")
plt.gca().invert_xaxis()

# plt.savefig('../figures/Mean Misalignment Curves by Halo', dpi=140)
# plt.close()
#plt.show()












