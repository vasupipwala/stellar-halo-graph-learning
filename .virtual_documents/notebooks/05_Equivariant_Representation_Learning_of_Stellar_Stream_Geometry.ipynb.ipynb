import numpy as np
import astropy.units as u
import matplotlib.pyplot as plt
import pickle
import datetime
import platform
import gala
import astropy
from astropy.coordinates import CartesianRepresentation, CartesianDifferential
from sklearn.decomposition import PCA
from scipy.ndimage import uniform_filter1d
from sklearn.metrics import r2_score
import pandas as pd
from scipy.stats import f_oneway
from scipy.fft import rfft, rfftfreq
from scipy.signal import detrend
from sklearn.preprocessing import StandardScaler
from scipy.stats import spearmanr
from scipy.stats import pearsonr
from sklearn.metrics import silhouette_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

from matplotlib.colors import Normalize
from matplotlib.cm import ScalarMappable
from mpl_toolkits.axes_grid1 import make_axes_locatable
from matplotlib.lines import Line2D
import seaborn as sns

from gala.units import galactic
from gala.potential import Hamiltonian
from gala.potential import LogarithmicPotential
from gala.dynamics import PhaseSpacePosition
from gala.dynamics.actionangle import find_actions_o2gf
from gala.dynamics.mockstream import (
    MockStreamGenerator,
    FardalStreamDF
)
from gala.integrate import LeapfrogIntegrator


from tqdm.notebook import tqdm
import time
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.animation import FuncAnimation
from matplotlib.animation import FFMpegWriter


import torch
from torch_geometric.data import Data
from torch_geometric.nn import knn_graph
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GraphConv, global_mean_pool
from torch_geometric.loader import DataLoader
from torch_geometric.data import Batch
import copy

np.random.seed(42)
print(torch.__version__)


with open("../data/gc_stream_ensemble.pkl", "rb") as f:
    data = pickle.load(f)

streams = data["streams"]


def make_galactic_hamiltonian(q=1.0):
    pot = LogarithmicPotential(
        v_c=220 * u.km/u.s,
        r_h=12 * u.kpc,
        q1=1.0,
        q2=1.0,
        q3=q,
        units=galactic
    )
    return Hamiltonian(pot)


def initial_progenitor_phase_space():
    """
    Initial phase-space position of the progenitor globular cluster.
    """
    pos = [8.5, 0.0, 5.0] * u.kpc
    vel = [0.0, 180.0, 60.0] * u.km/u.s
    return PhaseSpacePosition(pos=pos, vel=vel)


def extract_stream_snapshot(stream_tuple, t_array, time_index=0):

    mock = stream_tuple[0]
    nt = len(t_array)

    total_points = mock.pos.x.shape[0]

    if total_points % nt != 0:
        raise ValueError(
            "Total points not divisible by number of time steps."
        )

    npart = total_points // nt

    # Reshape to (nt, npart)
    x_all = mock.pos.x.reshape(nt, npart)
    y_all = mock.pos.y.reshape(nt, npart)
    z_all = mock.pos.z.reshape(nt, npart)

    vx_all = mock.vel.d_x.reshape(nt, npart)
    vy_all = mock.vel.d_y.reshape(nt, npart)
    vz_all = mock.vel.d_z.reshape(nt, npart)

    # IMPORTANT: Reverse time axis if needed
    # Because stream storage is often reversed relative to t_array
    x_all = x_all[::-1]
    y_all = y_all[::-1]
    z_all = z_all[::-1]

    vx_all = vx_all[::-1]
    vy_all = vy_all[::-1]
    vz_all = vz_all[::-1]

    # Extract requested epoch
    x = x_all[time_index]
    y = y_all[time_index]
    z = z_all[time_index]

    vx = vx_all[time_index]
    vy = vy_all[time_index]
    vz = vz_all[time_index]

    pos = CartesianRepresentation(x, y, z)
    vel = CartesianDifferential(vx, vy, vz)

    pos = pos.with_differentials(vel)

    return PhaseSpacePosition(pos)





def build_stream_graph(stream_snapshot, halo_id, k=16, device="cpu"):
    """
    Build a stream graph from a phase-space snapshot.

    Node features:
        (x, y, z, vx, vy, vz, r)

    Edge features:
        scalar distance

    Parameters
    ----------
    stream_snapshot : gala PhaseSpacePosition
    halo_id : int
    k : int
    device : str
    """

    # -----------------------------------
    # Extract phase-space
    # -----------------------------------
    pos = stream_snapshot.pos.xyz.T.to_value()
    vel = stream_snapshot.vel.d_xyz.T.to_value()

    pos = torch.tensor(pos, dtype=torch.float, device=device)
    vel = torch.tensor(vel, dtype=torch.float, device=device)

    # -----------------------------------
    # Center positions (translation invariance)
    # -----------------------------------
    pos = pos - pos.mean(dim=0, keepdim=True)

    # -----------------------------------
    # Radial magnitude (internal geometry)
    # -----------------------------------
    r = torch.norm(pos, dim=1, keepdim=True)

    # -----------------------------------
    # Velocity normalization (stable training)
    # -----------------------------------
    vel_std = vel.std(dim=0, keepdim=True) + 1e-8
    vel = vel / vel_std

    # -----------------------------------
    # Delegate graph construction
    # -----------------------------------
    graph = build_knn_graph(
        pos=pos,
        vel=vel,
        r=r,
        halo_id=torch.tensor([halo_id], device=device),
        k=k
    )

    return graph


def random_rotation_matrix(device="cpu"):
    """
    Generate random 3D rotation matrix using unit quaternion.
    Uniform over SO(3).
    """

    q = torch.randn(4, device=device)
    q = q / torch.norm(q)

    w, x, y, z = q

    R = torch.stack([
        torch.stack([1 - 2*(y**2 + z**2),
                     2*(x*y - z*w),
                     2*(x*z + y*w)]),

        torch.stack([2*(x*y + z*w),
                     1 - 2*(x**2 + z**2),
                     2*(y*z - x*w)]),

        torch.stack([2*(x*z - y*w),
                     2*(y*z + x*w),
                     1 - 2*(x**2 + y**2)])
    ])

    return R.float()


def add_position_noise(pos, noise_fraction=0.005):
    """
    Add small isotropic Gaussian noise scaled to RMS radius.
    """

    rms = torch.sqrt(torch.mean(torch.sum(pos**2, dim=1)))
    scale = noise_fraction * rms

    noise = scale * torch.randn_like(pos)

    return pos + noise

def build_knn_graph(pos, vel, r, halo_id, k=16):
    """
    Build kNN graph with 7D node features.
    """

    device = pos.device
    N = pos.size(0)
    k = min(k, N - 1)

    # -----------------------------------
    # Node features: (x,y,z,vx,vy,vz,r)
    # -----------------------------------
    x = torch.cat([pos, vel, r], dim=1)

    # -----------------------------------
    # kNN in position space
    # -----------------------------------
    with torch.no_grad():
        dist = torch.cdist(pos, pos)
        knn_idx = dist.topk(k=k+1, largest=False).indices[:, 1:]

    row = torch.arange(N, device=device).unsqueeze(1).repeat(1, k).flatten()
    col = knn_idx.flatten()

    edge_index = torch.stack([row, col], dim=0)

    # -----------------------------------
    # Edge features: scalar distance only
    # -----------------------------------
    edge_attr = dist[row, col].unsqueeze(1)

    return Data(
        x=x,
        pos=pos,
        edge_index=edge_index,
        edge_attr=edge_attr,
        halo_id=halo_id
    )

def subsample_graph(data, keep_ratio=0.9, k=16):
    """
    Subsample nodes and rebuild graph consistently.
    """

    device = data.x.device
    N = data.x.size(0)

    keep_N = max(16, int(N * keep_ratio))
    keep_N = min(keep_N, N)

    k = min(k, keep_N - 1)

    # Random node selection
    idx = torch.randperm(N, device=device)[:keep_N]

    # Extract position + velocity correctly
    pos = data.pos[idx]
    vel = data.x[idx][:, 3:6]

    # Recompute radial magnitude
    r = torch.norm(pos, dim=1, keepdim=True)

    return build_knn_graph(
        pos=pos,
        vel=vel,
        r=r,
        halo_id=data.halo_id,
        k=k
    )

def augment_graph(data, k=16, keep_ratio=0.9):
    """
    Physics-preserving augmentation:
        - SO(3) rotation
        - Small position noise
        - Optional subsampling
    """

    device = data.pos.device

    # -----------------------------------
    # Extract clean tensors
    # -----------------------------------
    pos = data.pos.clone()
    vel = data.x[:, 3:6].clone()   # velocities only

    # -----------------------------------
    # 1️⃣ Random rotation (SO(3))
    # -----------------------------------
    R = random_rotation_matrix(device=device)

    pos = pos @ R.T
    vel = vel @ R.T

    # -----------------------------------
    # 2️⃣ Small isotropic position noise
    # -----------------------------------
    pos = add_position_noise(pos, noise_fraction=0.003)

    # -----------------------------------
    # 3️⃣ Recompute invariant radial magnitude
    # -----------------------------------
    r = torch.norm(pos, dim=1, keepdim=True)

    # -----------------------------------
    # 4️⃣ Rebuild graph (full features)
    # -----------------------------------
    augmented = build_knn_graph(
        pos=pos,
        vel=vel,
        r=r,
        halo_id=data.halo_id,
        k=k
    )

    # -----------------------------------
    # 5️⃣ Optional subsampling
    # -----------------------------------
    if keep_ratio < 1.0:
        augmented = subsample_graph(
            augmented,
            keep_ratio=keep_ratio,
            k=k
        )

    return augmented

def generate_contrastive_pair(graph, k=16, keep_ratio=0.9):

    g1 = augment_graph(graph, k=k, keep_ratio=keep_ratio)
    g2 = augment_graph(graph, k=k, keep_ratio=keep_ratio)

    return g1, g2


halo_mapping = {
    "spherical": 0,
    "oblate": 1,
    "prolate": 2
}

graph_list = []
stream_metadata = []

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --------------------------------------------
# Choose number of time samples
# --------------------------------------------
n_time_samples = 8   # ≈ 9 streams × 8 = 72 graphs total

for s in streams:

    halo_id = halo_mapping[s["halo"]]
    total_time_steps = len(s["t"])

    # Store metadata for optional dynamic sampling later
    stream_metadata.append({
        "stream": s["stream"],
        "time_array": s["t"],
        "halo_id": halo_id
    })

    # --------------------------------------------
    # Uniform time sampling across evolution
    # --------------------------------------------
    time_indices = np.linspace(
        0,
        total_time_steps - 1,
        n_time_samples
    ).astype(int)

    for t_idx in time_indices:

        stream_snapshot = extract_stream_snapshot(
            s["stream"],
            s["t"],
            time_index=int(t_idx)
        )

        graph = build_stream_graph(
            stream_snapshot,
            halo_id=halo_id,
            k=16,
            device=device
        )

        # Store time index as scalar tensor (cleaner)
        graph.time_index = torch.tensor(t_idx, device=device)

        graph_list.append(graph)

print("Total graphs:", len(graph_list))

# Safer count per halo
from collections import Counter
halo_counts = Counter([int(g.halo_id.item()) for g in graph_list])

print("Graphs per halo:", halo_counts)


graph_list


loader = DataLoader(
    graph_list,
    batch_size=9,   # all graphs at once (since only 9)
    shuffle=True
)


g = graph_list[0]

print("Node feature shape:", g.x.shape)
print("Edge index shape:", g.edge_index.shape)
print("Edge attr shape:", g.edge_attr.shape)
print("Halo ID:", g.halo_id)


model = EGNNEncoder()
test_emb = model(graph_list[0])
print("Embedding shape:", test_emb.shape)


g1, g2 = generate_contrastive_pair(graph_list[0])

print("Augmented 1 nodes:", g1.x.shape)
print("Augmented 2 nodes:", g2.x.shape)


class EGNNLayer(nn.Module):

    def __init__(self, in_features, hidden_features):
        super().__init__()

        self.edge_mlp = nn.Sequential(
            nn.Linear(in_features * 2 + 1, hidden_features),
            nn.SiLU(),
            nn.Linear(hidden_features, hidden_features),
            nn.SiLU()
        )

        self.node_mlp = nn.Sequential(
            nn.Linear(hidden_features + in_features, hidden_features),
            nn.SiLU(),
            nn.Linear(hidden_features, hidden_features)
        )

    def forward(self, x, pos, edge_index):

        row, col = edge_index
    
        rel_pos = pos[row] - pos[col]
        dist2 = torch.sum(rel_pos**2, dim=1, keepdim=True)
    
        edge_input = torch.cat([x[row], x[col], dist2], dim=1)
        edge_feat = self.edge_mlp(edge_input)
    
        agg = torch.zeros(
            x.size(0),
            edge_feat.size(1),
            device=x.device
        )
        agg.index_add_(0, row, edge_feat)
    
        update = self.node_mlp(torch.cat([x, agg], dim=1))
    
        x = x + update  # ← residual connection
    
        return x

class EGNNEncoder(nn.Module):

    def __init__(self, in_features=7, hidden=64, layers=3, emb_dim=8):
        super().__init__()

        self.layers = nn.ModuleList([
            EGNNLayer(in_features if i == 0 else hidden, hidden)
            for i in range(layers)
        ])

        self.lin = nn.Linear(hidden, emb_dim)

    def forward(self, data):

        x, pos, edge_index = data.x, data.pos, data.edge_index
        batch = data.batch  # required for batching

        for layer in self.layers:
            x = layer(x, pos, edge_index)

        # Graph-level pooling
        graph_embedding = global_mean_pool(x, batch)

        z = self.lin(graph_embedding)

        return z


batch = next(iter(loader))
print(batch)
print(batch.x.shape)
print(batch.batch.shape)





def supervised_contrastive_loss(z, labels, tau=0.1):

    # Normalize embeddings
    z = F.normalize(z, dim=1)

    # Similarity matrix
    sim = torch.matmul(z, z.T) / tau

    # Remove self-similarity
    mask = torch.eye(z.size(0), device=z.device).bool()
    sim.masked_fill_(mask, -1e9)

    labels = labels.view(-1, 1)

    # Positive mask
    positive_mask = (labels == labels.T).float()
    positive_mask = positive_mask * (~mask)

    # Log-softmax (stable)
    log_prob = sim - torch.logsumexp(sim, dim=1, keepdim=True)

    # Count positives per sample
    pos_count = positive_mask.sum(dim=1)

    # Avoid division by zero
    pos_count = torch.clamp(pos_count, min=1.0)

    loss = - (positive_mask * log_prob).sum(dim=1) / pos_count

    return loss.mean()

def generate_contrastive_batch(graph_list, device, k=16):

    augmented_graphs = []

    for graph in graph_list:

        g1 = augment_graph(graph, k=k)
        g2 = augment_graph(graph, k=k)

        augmented_graphs.append(g1)
        augmented_graphs.append(g2)

    batch = Batch.from_data_list(augmented_graphs)
    batch = batch.to(device)

    return batch

# def generate_contrastive_batch(stream_metadata, k=16):

#     augmented_graphs = []

#     for meta in stream_metadata:

#         total_time_steps = len(meta["time_array"])

#         # Random time index each epoch
#         t_idx = np.random.randint(0, total_time_steps)

#         stream_snapshot = extract_stream_snapshot(
#             meta["stream"],
#             meta["time_array"],
#             time_index=t_idx
#         )

#         base_graph = build_stream_graph(
#             stream_snapshot,
#             halo_id=meta["halo_id"],
#             k=k
#         )

#         # Two augmentations
#         g1 = augment_graph(base_graph, k=k)
#         g2 = augment_graph(base_graph, k=k)

#         augmented_graphs.append(g1)
#         augmented_graphs.append(g2)

#     loader = DataLoader(
#         augmented_graphs,
#         batch_size=len(augmented_graphs),
#         shuffle=False
#     )

#     return next(iter(loader))


epochs = 500
tau = 0.1

patience = 80
min_epochs = 120
best_loss = float("inf")
no_improve_counter = 0

loss_history = []

start_time = time.time()

print("Starting training...\n")

for epoch in tqdm(range(epochs)):

    # ==========================
    # TRAIN STEP
    # ==========================
    model.train()
    optimizer.zero_grad()

    batch = generate_contrastive_batch(
        graph_list,
        device=device
    )

    labels = batch.halo_id.view(-1)

    z = model(batch)

    loss = supervised_contrastive_loss(z, labels, tau=tau)

    loss.backward()
    optimizer.step()

    loss_val = loss.item()
    loss_history.append(loss_val)

    # ==========================
    # EARLY STOPPING
    # ==========================
    if loss_val < best_loss - 1e-4:
        best_loss = loss_val
        no_improve_counter = 0
    else:
        no_improve_counter += 1

    if epoch > min_epochs and no_improve_counter > patience:
        print(f"\nStopping early at epoch {epoch}")
        break

    # ==========================
    # MONITORING
    # ==========================
    if epoch % 25 == 0:

        model.eval()
        with torch.no_grad():

            # Evaluate on ORIGINAL graphs (no augmentation)
            eval_batch = Batch.from_data_list(graph_list).to(device)

            z_eval = model(eval_batch)

            embedding_norm = torch.norm(z_eval, dim=1).mean().item()

            z_np = z_eval.cpu().numpy()
            labels_np = eval_batch.halo_id.view(-1).cpu().numpy()

            sil_score = silhouette_score(z_np, labels_np)

        elapsed = time.time() - start_time
        progress = (epoch + 1) / epochs
        eta = elapsed * (1 - progress) / max(progress, 1e-8)

        print(f"\nEpoch {epoch}")
        print(f"Loss: {loss_val:.4f}")
        print(f"Silhouette: {sil_score:.4f}")
        print(f"Embedding norm: {embedding_norm}")
        print(f"Elapsed: {elapsed:.1f}s | ETA: {eta:.1f}s")
        print("-" * 50)

total_time = time.time() - start_time

print("\nTraining complete.")
print(f"Total time: {total_time:.2f} seconds")


model.eval()
batch = generate_contrastive_batch(graph_list)
batch = batch.to(device)

with torch.no_grad():
    z = model(batch).cpu().numpy()

labels = batch.halo_id.cpu().numpy()

clf = LogisticRegression().fit(z, labels)
preds = clf.predict(z)

acc = accuracy_score(labels, preds)

print("Linear probe accuracy:", acc)


model.eval()

#loader = DataLoader(graph_list, batch_size=9)

with torch.no_grad():
    batch = next(iter(loader)).to(device)
    embeddings = model(batch)  # (9, 8)

embeddings = embeddings.cpu()


pca = PCA(n_components=2)
emb_2d = pca.fit_transform(embeddings)

labels = [g.halo_id.item() for g in graph_list]

plt.figure(figsize=(6,5))
scatter = plt.scatter(emb_2d[:,0], emb_2d[:,1], c=labels, s=120)
plt.title("Contrastive Stream Embeddings")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.grid(alpha=0.3)
plt.show()



