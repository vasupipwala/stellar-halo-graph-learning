{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb82a34-170d-48e9-800a-b323f4e97950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "import platform\n",
    "import gala\n",
    "import astropy\n",
    "from astropy.coordinates import CartesianRepresentation, CartesianDifferential\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.signal import detrend\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from gala.units import galactic\n",
    "from gala.potential import Hamiltonian\n",
    "from gala.potential import LogarithmicPotential\n",
    "from gala.dynamics import PhaseSpacePosition\n",
    "from gala.dynamics.actionangle import find_actions_o2gf\n",
    "from gala.dynamics.mockstream import (\n",
    "    MockStreamGenerator,\n",
    "    FardalStreamDF\n",
    ")\n",
    "from gala.integrate import LeapfrogIntegrator\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.animation import FFMpegWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0618bca0-15a1-45ad-8ccd-5324bbcf0c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vasu/anaconda3/lib/python3.11/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: dlopen(/Users/vasu/anaconda3/lib/python3.11/site-packages/torch_scatter/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN3c1017RegisterOperatorsD1Ev'\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/Users/vasu/anaconda3/lib/python3.11/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: dlopen(/Users/vasu/anaconda3/lib/python3.11/site-packages/torch_cluster/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN3c1017RegisterOperatorsD1Ev'\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/Users/vasu/anaconda3/lib/python3.11/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: dlopen(/Users/vasu/anaconda3/lib/python3.11/site-packages/torch_spline_conv/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN3c1017RegisterOperatorsD1Ev'\n",
      "  warnings.warn(\n",
      "/Users/vasu/anaconda3/lib/python3.11/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/vasu/anaconda3/lib/python3.11/site-packages/torch_sparse/_version_cpu.so, 0x0006): symbol not found in flat namespace '__ZN3c1017RegisterOperatorsD1Ev'\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "import copy\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65408c15-cafd-47ed-9c10-f1e5c92eec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed9e78d-1212-44f7-b0b8-181fb1b9513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12907b4-cd99-4ba3-94bd-a2d2b3b727ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/gc_stream_ensemble.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "streams = data[\"streams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b1757d7-6864-4ad6-be48-07fdc452a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 16\n",
    "hidden=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258708a1-bd29-4538-9389-8962594a6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_galactic_hamiltonian(q=1.0):\n",
    "    pot = LogarithmicPotential(\n",
    "        v_c=220 * u.km/u.s,\n",
    "        r_h=12 * u.kpc,\n",
    "        q1=1.0,\n",
    "        q2=1.0,\n",
    "        q3=q,\n",
    "        units=galactic\n",
    "    )\n",
    "    return Hamiltonian(pot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d8ee1d-5232-4085-b889-f410b0409cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_progenitor_phase_space():\n",
    "    \"\"\"\n",
    "    Initial phase-space position of the progenitor globular cluster.\n",
    "    \"\"\"\n",
    "    pos = [8.5, 0.0, 5.0] * u.kpc\n",
    "    vel = [0.0, 180.0, 60.0] * u.km/u.s\n",
    "    return PhaseSpacePosition(pos=pos, vel=vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29072e0a-71ce-499a-b488-94bdfbde066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stream_snapshot(stream_tuple, t_array, time_index=0):\n",
    "\n",
    "    mock = stream_tuple[0]\n",
    "    nt = len(t_array)\n",
    "\n",
    "    total_points = mock.pos.x.shape[0]\n",
    "\n",
    "    if total_points % nt != 0:\n",
    "        raise ValueError(\n",
    "            \"Total points not divisible by number of time steps.\"\n",
    "        )\n",
    "\n",
    "    npart = total_points // nt\n",
    "\n",
    "    # Reshape to (nt, npart)\n",
    "    x_all = mock.pos.x.reshape(nt, npart)\n",
    "    y_all = mock.pos.y.reshape(nt, npart)\n",
    "    z_all = mock.pos.z.reshape(nt, npart)\n",
    "\n",
    "    vx_all = mock.vel.d_x.reshape(nt, npart)\n",
    "    vy_all = mock.vel.d_y.reshape(nt, npart)\n",
    "    vz_all = mock.vel.d_z.reshape(nt, npart)\n",
    "\n",
    "    # IMPORTANT: Reverse time axis if needed\n",
    "    # Because stream storage is often reversed relative to t_array\n",
    "    x_all = x_all[::-1]\n",
    "    y_all = y_all[::-1]\n",
    "    z_all = z_all[::-1]\n",
    "\n",
    "    vx_all = vx_all[::-1]\n",
    "    vy_all = vy_all[::-1]\n",
    "    vz_all = vz_all[::-1]\n",
    "\n",
    "    # Extract requested epoch\n",
    "    x = x_all[time_index]\n",
    "    y = y_all[time_index]\n",
    "    z = z_all[time_index]\n",
    "\n",
    "    vx = vx_all[time_index]\n",
    "    vy = vy_all[time_index]\n",
    "    vz = vz_all[time_index]\n",
    "\n",
    "    pos = CartesianRepresentation(x, y, z)\n",
    "    vel = CartesianDifferential(vx, vy, vz)\n",
    "\n",
    "    pos = pos.with_differentials(vel)\n",
    "\n",
    "    return PhaseSpacePosition(pos)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b5560c6-46a6-40da-8a1e-e29a3709a340",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def build_stream_graph(stream_snapshot, halo_id, k=8, \n",
    "                       max_nodes=1500, device=\"cpu\"):\n",
    "\n",
    "    pos = stream_snapshot.pos.xyz.T.to_value()\n",
    "    vel = stream_snapshot.vel.d_xyz.T.to_value()\n",
    "\n",
    "    pos = torch.tensor(pos, dtype=torch.float, device=device)\n",
    "    vel = torch.tensor(vel, dtype=torch.float, device=device)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Subsample BEFORE graph construction\n",
    "    # -----------------------------------\n",
    "    N = pos.size(0)\n",
    "    if N > max_nodes:\n",
    "        idx = torch.randperm(N)[:max_nodes]\n",
    "        pos = pos[idx]\n",
    "        vel = vel[idx]\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Center positions\n",
    "    # -----------------------------------\n",
    "    pos = pos - pos.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Internal radial magnitude\n",
    "    # -----------------------------------\n",
    "    r = torch.norm(pos, dim=1, keepdim=True)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Velocity normalization\n",
    "    # -----------------------------------\n",
    "    vel = vel / (vel.std(dim=0, keepdim=True) + 1e-8)\n",
    "\n",
    "    # Node features: (x,y,z,vx,vy,vz,r)\n",
    "    x = torch.cat([pos, vel, r], dim=1)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Build kNN graph (k=8)\n",
    "    # -----------------------------------\n",
    "    graph = build_knn_graph(\n",
    "        pos=pos,\n",
    "        vel=vel,\n",
    "        halo_id=torch.tensor([halo_id], device=device),\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f20a2f7e-88ac-496e-8900-14f21e42c235",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def build_stream_graph(stream_snapshot, halo_id, k=k, max_nodes=1500, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Build a stream graph from a phase-space snapshot.\n",
    "\n",
    "    Node features:\n",
    "        (x, y, z, vx, vy, vz, r)\n",
    "\n",
    "    Edge features:\n",
    "        scalar distance\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stream_snapshot : gala PhaseSpacePosition\n",
    "    halo_id : int\n",
    "    k : int\n",
    "    device : str\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Extract phase-space\n",
    "    # -----------------------------------\n",
    "    pos = stream_snapshot.pos.xyz.T.to_value()\n",
    "    vel = stream_snapshot.vel.d_xyz.T.to_value()\n",
    "\n",
    "    pos = torch.tensor(pos, dtype=torch.float, device=device)\n",
    "    vel = torch.tensor(vel, dtype=torch.float, device=device)\n",
    "\n",
    "     # -----------------------------------\n",
    "    # Subsample BEFORE graph construction\n",
    "    # -----------------------------------\n",
    "    N = pos.size(0)\n",
    "    if N > max_nodes:\n",
    "        idx = torch.randperm(N)[:max_nodes]\n",
    "        pos = pos[idx]\n",
    "        vel = vel[idx]\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Center positions (translation invariance)\n",
    "    # -----------------------------------\n",
    "    pos = pos - pos.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Radial magnitude (internal geometry)\n",
    "    # -----------------------------------\n",
    "    r = torch.norm(pos, dim=1, keepdim=True)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Velocity normalization (stable training)\n",
    "    # -----------------------------------\n",
    "    vel_std = vel.std(dim=0, keepdim=True) + 1e-8\n",
    "    vel = vel / vel_std\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Delegate graph construction\n",
    "    # -----------------------------------\n",
    "    graph = build_knn_graph(\n",
    "        pos=pos,\n",
    "        vel=vel,\n",
    "        r=r,\n",
    "        halo_id=torch.tensor([halo_id], device=device),\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaeefae1-5691-46ab-8916-15b96f797b95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def random_rotation_matrix(device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Generate random 3D rotation matrix using unit quaternion.\n",
    "    Uniform over SO(3).\n",
    "    \"\"\"\n",
    "\n",
    "    q = torch.randn(4, device=device)\n",
    "    q = q / torch.norm(q)\n",
    "\n",
    "    w, x, y, z = q\n",
    "\n",
    "    R = torch.stack([\n",
    "        torch.stack([1 - 2*(y**2 + z**2),\n",
    "                     2*(x*y - z*w),\n",
    "                     2*(x*z + y*w)]),\n",
    "\n",
    "        torch.stack([2*(x*y + z*w),\n",
    "                     1 - 2*(x**2 + z**2),\n",
    "                     2*(y*z - x*w)]),\n",
    "\n",
    "        torch.stack([2*(x*z - y*w),\n",
    "                     2*(y*z + x*w),\n",
    "                     1 - 2*(x**2 + y**2)])\n",
    "    ])\n",
    "\n",
    "    return R.float()\n",
    "\n",
    "\n",
    "def add_position_noise(pos, noise_fraction=0.005):\n",
    "    \"\"\"\n",
    "    Add small isotropic Gaussian noise scaled to RMS radius.\n",
    "    \"\"\"\n",
    "\n",
    "    rms = torch.sqrt(torch.mean(torch.sum(pos**2, dim=1)))\n",
    "    scale = noise_fraction * rms\n",
    "\n",
    "    noise = scale * torch.randn_like(pos)\n",
    "\n",
    "    return pos + noise\n",
    "\n",
    "def build_knn_graph(pos, vel, r, halo_id, k=k):\n",
    "    \"\"\"\n",
    "    Build kNN graph with 7D node features.\n",
    "    \"\"\"\n",
    "\n",
    "    device = pos.device\n",
    "    N = pos.size(0)\n",
    "    k = min(k, N - 1)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Node features: (x,y,z,vx,vy,vz,r)\n",
    "    # -----------------------------------\n",
    "    x = torch.cat([pos, vel, r], dim=1)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # kNN in position space\n",
    "    # -----------------------------------\n",
    "    with torch.no_grad():\n",
    "        dist = torch.cdist(pos, pos)\n",
    "        knn_idx = dist.topk(k=k+1, largest=False).indices[:, 1:]\n",
    "\n",
    "    row = torch.arange(N, device=device).unsqueeze(1).repeat(1, k).flatten()\n",
    "    col = knn_idx.flatten()\n",
    "\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Edge features: scalar distance only\n",
    "    # -----------------------------------\n",
    "    edge_attr = dist[row, col].unsqueeze(1)\n",
    "\n",
    "    return Data(\n",
    "        x=x,\n",
    "        pos=pos,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        halo_id=halo_id\n",
    "    )\n",
    "\n",
    "def subsample_graph(data, keep_ratio=0.9, k=k):\n",
    "    \"\"\"\n",
    "    Subsample nodes and rebuild graph consistently.\n",
    "    \"\"\"\n",
    "\n",
    "    device = data.x.device\n",
    "    N = data.x.size(0)\n",
    "\n",
    "    keep_N = max(16, int(N * keep_ratio))\n",
    "    keep_N = min(keep_N, N)\n",
    "\n",
    "    k = min(k, keep_N - 1)\n",
    "\n",
    "    # Random node selection\n",
    "    idx = torch.randperm(N, device=device)[:keep_N]\n",
    "\n",
    "    # Extract position + velocity correctly\n",
    "    pos = data.pos[idx]\n",
    "    vel = data.x[idx][:, 3:6]\n",
    "\n",
    "    # Recompute radial magnitude\n",
    "    r = torch.norm(pos, dim=1, keepdim=True)\n",
    "\n",
    "    return build_knn_graph(\n",
    "        pos=pos,\n",
    "        vel=vel,\n",
    "        r=r,\n",
    "        halo_id=data.halo_id,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "def augment_graph(data, k=k, keep_ratio=0.9):\n",
    "    \"\"\"\n",
    "    Physics-preserving augmentation:\n",
    "        - SO(3) rotation\n",
    "        - Small position noise\n",
    "        - Optional subsampling\n",
    "    \"\"\"\n",
    "\n",
    "    device = data.pos.device\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Extract clean tensors\n",
    "    # -----------------------------------\n",
    "    pos = data.pos.clone()\n",
    "    vel = data.x[:, 3:6].clone()   # velocities only\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 1Ô∏è‚É£ Random rotation (SO(3))\n",
    "    # -----------------------------------\n",
    "    R = random_rotation_matrix(device=device)\n",
    "\n",
    "    pos = pos @ R.T\n",
    "    vel = vel @ R.T\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 2Ô∏è‚É£ Small isotropic position noise\n",
    "    # -----------------------------------\n",
    "    pos = add_position_noise(pos, noise_fraction=0.003)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 3Ô∏è‚É£ Recompute invariant radial magnitude\n",
    "    # -----------------------------------\n",
    "    r = torch.norm(pos, dim=1, keepdim=True)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 4Ô∏è‚É£ Rebuild graph (full features)\n",
    "    # -----------------------------------\n",
    "    augmented = build_knn_graph(\n",
    "        pos=pos,\n",
    "        vel=vel,\n",
    "        r=r,\n",
    "        halo_id=data.halo_id,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 5Ô∏è‚É£ Optional subsampling\n",
    "    # -----------------------------------\n",
    "    if keep_ratio < 1.0:\n",
    "        augmented = subsample_graph(\n",
    "            augmented,\n",
    "            keep_ratio=keep_ratio,\n",
    "            k=k\n",
    "        )\n",
    "\n",
    "    return augmented\n",
    "\n",
    "# def generate_contrastive_pair(graph, k=k, keep_ratio=0.9):\n",
    "\n",
    "#     g1 = augment_graph(graph, k=k, keep_ratio=keep_ratio)\n",
    "#     g2 = augment_graph(graph, k=k, keep_ratio=keep_ratio)\n",
    "\n",
    "#     return g1, g2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91c36588-d859-45e0-8f68-4c181c1bfd92",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "halo_mapping = {\n",
    "    \"spherical\": 0,\n",
    "    \"oblate\": 1,\n",
    "    \"prolate\": 2\n",
    "}\n",
    "\n",
    "graph_list = []\n",
    "stream_metadata = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_time_samples = 4   # minimal but sufficient\n",
    "\n",
    "stream_id_counter = 0\n",
    "\n",
    "for s in streams:\n",
    "\n",
    "    halo_id = halo_mapping[s[\"halo\"]]\n",
    "    halo_name = s[\"halo\"]\n",
    "\n",
    "    total_time_steps = len(s[\"t\"])\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Store COMPLETE stream metadata\n",
    "    # --------------------------------------------\n",
    "    stream_metadata.append({\n",
    "        \"stream_id\": stream_id_counter,\n",
    "        \"stream_object\": s[\"stream\"],\n",
    "        \"time_array\": s[\"t\"],\n",
    "        \"halo_id\": halo_id,\n",
    "        \"halo_name\": halo_name,\n",
    "        \"n_time_steps\": total_time_steps\n",
    "    })\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Uniform time sampling (for evaluation set)\n",
    "    # --------------------------------------------\n",
    "    time_indices = np.linspace(\n",
    "        0,\n",
    "        total_time_steps - 1,\n",
    "        n_time_samples\n",
    "    ).astype(int)\n",
    "\n",
    "    for t_idx in time_indices:\n",
    "\n",
    "        stream_snapshot = extract_stream_snapshot(\n",
    "            s[\"stream\"],\n",
    "            s[\"t\"],\n",
    "            time_index=int(t_idx)\n",
    "        )\n",
    "\n",
    "        graph = build_stream_graph(\n",
    "            stream_snapshot,\n",
    "            halo_id=halo_id,\n",
    "            k=k,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        graph.time_index = torch.tensor(int(t_idx), device=device)\n",
    "        graph.stream_id = torch.tensor(stream_id_counter, device=device)\n",
    "\n",
    "        graph_list.append(graph)\n",
    "\n",
    "    stream_id_counter += 1\n",
    "\n",
    "\n",
    "print(\"Total graphs:\", len(graph_list))\n",
    "\n",
    "halo_counts = Counter([int(g.halo_id.item()) for g in graph_list])\n",
    "print(\"Graphs per halo:\", halo_counts)\n",
    "\n",
    "print(\"Total unique streams:\", len(stream_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f4ab838-11cc-4dc3-85d2-783a54f2cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stream_graph(stream_snapshot, halo_id, k=k, max_nodes=1500, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Build a stream graph from a phase-space snapshot.\n",
    "\n",
    "    Node features:\n",
    "        (x, y, z, vx, vy, vz)\n",
    "\n",
    "    Edge features:\n",
    "        scalar distance (rotation invariant)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stream_snapshot : gala PhaseSpacePosition\n",
    "    halo_id : int\n",
    "    k : int\n",
    "    max_nodes : int\n",
    "    device : str\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Extract phase-space\n",
    "    # -----------------------------------\n",
    "    pos = stream_snapshot.pos.xyz.T.to_value()\n",
    "    vel = stream_snapshot.vel.d_xyz.T.to_value()\n",
    "\n",
    "    pos = torch.tensor(pos, dtype=torch.float, device=device)\n",
    "    vel = torch.tensor(vel, dtype=torch.float, device=device)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Subsample BEFORE graph construction\n",
    "    # -----------------------------------\n",
    "    N = pos.size(0)\n",
    "    if N > max_nodes:\n",
    "        idx = torch.randperm(N, device=device)[:max_nodes]\n",
    "        pos = pos[idx]\n",
    "        vel = vel[idx]\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Center positions (translation invariance)\n",
    "    # -----------------------------------\n",
    "    pos = pos - pos.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Velocity normalization (per-stream)\n",
    "    # -----------------------------------\n",
    "    vel_std = vel.std(dim=0, keepdim=True) + 1e-8\n",
    "    vel = vel / vel_std\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Node features: pure 6D phase-space\n",
    "    # -----------------------------------\n",
    "    x = torch.cat([pos, vel], dim=1)   # (N,6)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Build kNN graph\n",
    "    # -----------------------------------\n",
    "    N = pos.size(0)\n",
    "    k = min(k, N - 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dist = torch.cdist(pos, pos)\n",
    "        knn_idx = dist.topk(k=k+1, largest=False).indices[:, 1:]\n",
    "\n",
    "    row = torch.arange(N, device=device).unsqueeze(1).repeat(1, k).flatten()\n",
    "    col = knn_idx.flatten()\n",
    "\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    # Edge feature: scalar distance only (rotation invariant)\n",
    "    edge_attr = dist[row, col].unsqueeze(1)\n",
    "\n",
    "    graph = Data(\n",
    "        x=x,\n",
    "        pos=pos,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        halo_id=torch.tensor([halo_id], device=device)\n",
    "    )\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a05c7c07-0346-4005-8dac-e3c72ed6ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def random_rotation_matrix(device=\"cpu\"):\n",
    "#     \"\"\"\n",
    "#     Generate random rotation matrix about the z-axis only.\n",
    "#     Preserves halo flattening axis (axisymmetry).\n",
    "\n",
    "#     Uniform over SO(2).\n",
    "#     \"\"\"\n",
    "\n",
    "#     theta = 2 * torch.pi * torch.rand(1, device=device)\n",
    "\n",
    "#     cos_t = torch.cos(theta)\n",
    "#     sin_t = torch.sin(theta)\n",
    "\n",
    "#     R = torch.tensor([\n",
    "#         [cos_t, -sin_t, torch.zeros_like(cos_t)],\n",
    "#         [sin_t,  cos_t, torch.zeros_like(cos_t)],\n",
    "#         [torch.zeros_like(cos_t),\n",
    "#          torch.zeros_like(cos_t),\n",
    "#          torch.ones_like(cos_t)]\n",
    "#     ], device=device)\n",
    "\n",
    "#     return R.squeeze().float()\n",
    "\n",
    "def random_small_rotation(device=\"cpu\", max_angle=0.2):\n",
    "    \"\"\"\n",
    "    Small random rotation around random axis.\n",
    "    max_angle in radians (~0.3 ‚âà 17 degrees)\n",
    "    \"\"\"\n",
    "    axis = torch.randn(3, device=device)\n",
    "    axis = axis / torch.norm(axis)\n",
    "\n",
    "    angle = torch.rand(1, device=device) * max_angle\n",
    "\n",
    "    K = torch.tensor([\n",
    "        [0, -axis[2], axis[1]],\n",
    "        [axis[2], 0, -axis[0]],\n",
    "        [-axis[1], axis[0], 0]\n",
    "    ], device=device)\n",
    "\n",
    "    R = torch.eye(3, device=device) + torch.sin(angle) * K + \\\n",
    "        (1 - torch.cos(angle)) * (K @ K)\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "def add_position_noise(pos, noise_fraction=0.005):\n",
    "    \"\"\"\n",
    "    Add small isotropic Gaussian noise scaled to RMS radius.\n",
    "    \"\"\"\n",
    "\n",
    "    rms = torch.sqrt(torch.mean(torch.sum(pos**2, dim=1)))\n",
    "    scale = noise_fraction * rms\n",
    "\n",
    "    noise = scale * torch.randn_like(pos)\n",
    "\n",
    "    return pos + noise\n",
    "\n",
    "\n",
    "def build_knn_graph(pos, vel, halo_id, k=k):\n",
    "    \"\"\"\n",
    "    Build kNN graph with 6D node features:\n",
    "        (x, y, z, vx, vy, vz)\n",
    "    \"\"\"\n",
    "\n",
    "    device = pos.device\n",
    "    N = pos.size(0)\n",
    "    k = min(k, N - 1)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Node features: (x,y,z,vx,vy,vz)\n",
    "    # -----------------------------------\n",
    "    x = torch.cat([pos, vel], dim=1)   # (N,6)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # kNN in position space\n",
    "    # -----------------------------------\n",
    "    with torch.no_grad():\n",
    "        dist = torch.cdist(pos, pos)\n",
    "        knn_idx = dist.topk(k=k+1, largest=False).indices[:, 1:]\n",
    "\n",
    "    row = torch.arange(N, device=device).unsqueeze(1).repeat(1, k).flatten()\n",
    "    col = knn_idx.flatten()\n",
    "\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    # Edge features: scalar distance (rotation invariant)\n",
    "    edge_attr = dist[row, col].unsqueeze(1)\n",
    "\n",
    "    return Data(\n",
    "        x=x,\n",
    "        pos=pos,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        halo_id=halo_id.clone()\n",
    "    )\n",
    "\n",
    "def subsample_graph(data, keep_ratio=0.9, k=k):\n",
    "    \"\"\"\n",
    "    Subsample nodes and rebuild graph consistently (6D setup).\n",
    "    \"\"\"\n",
    "\n",
    "    device = data.x.device\n",
    "    N = data.x.size(0)\n",
    "\n",
    "    if k is None:\n",
    "        k = 8\n",
    "\n",
    "    keep_N = max(16, int(N * keep_ratio))\n",
    "    keep_N = min(keep_N, N)\n",
    "    k = min(k, keep_N - 1)\n",
    "\n",
    "    idx = torch.randperm(N, device=device)[:keep_N]\n",
    "\n",
    "    pos = data.pos[idx]\n",
    "    vel = data.x[idx][:, 3:6]   # since x = (x,y,z,vx,vy,vz)\n",
    "\n",
    "    return build_knn_graph(\n",
    "        pos=pos,\n",
    "        vel=vel,\n",
    "        halo_id=data.halo_id,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "def augment_graph(data, k=k, keep_ratio=0.9):\n",
    "    \"\"\"\n",
    "    Physics-preserving augmentation:\n",
    "        - SO(2) rotation\n",
    "        - Small isotropic position noise\n",
    "        - Optional subsampling\n",
    "    \"\"\"\n",
    "\n",
    "    device = data.pos.device\n",
    "\n",
    "    if k is None:\n",
    "        k = 8\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Extract tensors\n",
    "    # -----------------------------------\n",
    "    pos = data.pos.clone()\n",
    "    vel = data.x[:, 3:6].clone()\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 1Ô∏è‚É£ Random rotation (SO(2))\n",
    "    # -----------------------------------\n",
    "    R = random_small_rotation(device=device, max_angle=0.2)\n",
    "\n",
    "    pos = pos @ R.T\n",
    "    vel = vel @ R.T\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 2Ô∏è‚É£ Small isotropic noise\n",
    "    # -----------------------------------\n",
    "    pos = add_position_noise(pos, noise_fraction=0.003)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 3Ô∏è‚É£ Rebuild graph (NO r anymore)\n",
    "    # -----------------------------------\n",
    "    augmented = build_knn_graph(\n",
    "        pos=pos,\n",
    "        vel=vel,\n",
    "        halo_id=data.halo_id,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 4Ô∏è‚É£ Optional subsampling\n",
    "    # -----------------------------------\n",
    "    if keep_ratio < 1.0:\n",
    "        augmented = subsample_graph(\n",
    "            augmented,\n",
    "            keep_ratio=keep_ratio,\n",
    "            k=k\n",
    "        )\n",
    "\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e25ace2f-4221-4e4e-83b9-dd21535a4a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluation graphs: 54\n",
      "Graphs per halo (evaluation): Counter({0: 18, 1: 18, 2: 18})\n",
      "Total unique streams: 9\n"
     ]
    }
   ],
   "source": [
    "halo_mapping = {\n",
    "    \"spherical\": 0,\n",
    "    \"oblate\": 1,\n",
    "    \"prolate\": 2\n",
    "}\n",
    "\n",
    "graph_list = []          # For clean evaluation only\n",
    "stream_metadata = []     # For dynamic training\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_time_samples = 6   # evaluation only\n",
    "stream_id_counter = 0\n",
    "\n",
    "for s in streams:\n",
    "\n",
    "    halo_id = halo_mapping[s[\"halo\"]]\n",
    "    halo_name = s[\"halo\"]\n",
    "\n",
    "    total_time_steps = len(s[\"t\"])\n",
    "\n",
    "    # ==========================================\n",
    "    # Store COMPLETE stream metadata\n",
    "    # ==========================================\n",
    "    stream_metadata.append({\n",
    "        \"stream_id\": stream_id_counter,\n",
    "        \"stream_object\": s[\"stream\"],\n",
    "        \"time_array\": s[\"t\"],\n",
    "        \"halo_id\": halo_id,\n",
    "        \"halo_name\": halo_name,\n",
    "        \"n_time_steps\": total_time_steps\n",
    "    })\n",
    "\n",
    "    # ==========================================\n",
    "    # Build CLEAN evaluation graphs (no augmentation)\n",
    "    # ==========================================\n",
    "    time_indices = np.linspace(\n",
    "        0,\n",
    "        total_time_steps - 1,\n",
    "        n_time_samples\n",
    "    ).astype(int)\n",
    "\n",
    "    for t_idx in time_indices:\n",
    "\n",
    "        snapshot = extract_stream_snapshot(\n",
    "            s[\"stream\"],\n",
    "            s[\"t\"],\n",
    "            time_index=int(t_idx)\n",
    "        )\n",
    "\n",
    "        graph = build_stream_graph(\n",
    "            snapshot,\n",
    "            halo_id=halo_id,\n",
    "            k=k,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Store identifiers (no gradients, no device complications)\n",
    "        graph.time_index = torch.tensor(int(t_idx))\n",
    "        graph.stream_id = torch.tensor(stream_id_counter)\n",
    "        graph.halo_id = torch.tensor([halo_id])\n",
    "\n",
    "        graph_list.append(graph)\n",
    "\n",
    "    stream_id_counter += 1\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Diagnostics\n",
    "# ==========================================\n",
    "\n",
    "print(\"Total evaluation graphs:\", len(graph_list))\n",
    "\n",
    "halo_counts = Counter([int(g.halo_id.item()) for g in graph_list])\n",
    "print(\"Graphs per halo (evaluation):\", halo_counts)\n",
    "\n",
    "print(\"Total unique streams:\", len(stream_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f577c9a-35ad-4fc8-8144-b49831085415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=0, stream_id=0),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=799, stream_id=0),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=1599, stream_id=0),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=2399, stream_id=0),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3199, stream_id=0),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3999, stream_id=0),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=0, stream_id=1),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=799, stream_id=1),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=1599, stream_id=1),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=2399, stream_id=1),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3199, stream_id=1),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3999, stream_id=1),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=0, stream_id=2),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=799, stream_id=2),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=1599, stream_id=2),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=2399, stream_id=2),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3199, stream_id=2),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3999, stream_id=2),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=0, stream_id=3),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=799, stream_id=3),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=1599, stream_id=3),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=2399, stream_id=3),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3199, stream_id=3),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3999, stream_id=3),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=0, stream_id=4),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=799, stream_id=4),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=1599, stream_id=4),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=2399, stream_id=4),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3199, stream_id=4),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3999, stream_id=4),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=0, stream_id=5),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=799, stream_id=5),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=1599, stream_id=5),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=2399, stream_id=5),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3199, stream_id=5),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3999, stream_id=5),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=0, stream_id=6),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=799, stream_id=6),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=1599, stream_id=6),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=2399, stream_id=6),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3199, stream_id=6),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3999, stream_id=6),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=0, stream_id=7),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=799, stream_id=7),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=1599, stream_id=7),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=2399, stream_id=7),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3199, stream_id=7),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3999, stream_id=7),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=0, stream_id=8),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=799, stream_id=8),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=1599, stream_id=8),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=2399, stream_id=8),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3199, stream_id=8),\n",
       " Data(x=[1500, 6], edge_index=[2, 24000], edge_attr=[24000, 1], pos=[1500, 3], halo_id=[1], time_index=3999, stream_id=8)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f7ae93-358e-4890-acda-1ea019a09249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = DataLoader(\n",
    "#     graph_list,\n",
    "#     batch_size=27,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     pin_memory=torch.cuda.is_available()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a68c7872-06e9-42f5-b0a3-dfe13c1e91a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature shape: torch.Size([1500, 6])\n",
      "Edge index shape: torch.Size([2, 24000])\n",
      "Edge attr shape: torch.Size([24000, 1])\n",
      "Halo ID: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "g = graph_list[0]\n",
    "\n",
    "print(\"Node feature shape:\", g.x.shape)\n",
    "print(\"Edge index shape:\", g.edge_index.shape)\n",
    "print(\"Edge attr shape:\", g.edge_attr.shape)\n",
    "print(\"Halo ID:\", g.halo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4fa9d5-020d-4197-bcd4-517b3ddae438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1, g2 = generate_contrastive_pair(graph_list[0], k=k)\n",
    "\n",
    "# print(\"Augmented 1 nodes:\", g1.x.shape)\n",
    "# print(\"Augmented 2 nodes:\", g2.x.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ade66c27-8e56-4c62-bb62-c4a7b066a36a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "class EGNNLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + 1, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "\n",
    "        row, col = edge_index\n",
    "\n",
    "        # Rotation-invariant squared distance\n",
    "        rel_pos = pos[row] - pos[col]\n",
    "        dist2 = torch.sum(rel_pos**2, dim=1, keepdim=True)\n",
    "\n",
    "        # Edge message\n",
    "        edge_input = torch.cat([x[row], x[col], dist2], dim=1)\n",
    "        edge_feat = self.edge_mlp(edge_input)\n",
    "\n",
    "        # Aggregate\n",
    "        agg = torch.zeros_like(x)\n",
    "        agg.index_add_(0, row, edge_feat)\n",
    "\n",
    "        # Node update\n",
    "        update = self.node_mlp(torch.cat([x, agg], dim=1))\n",
    "\n",
    "        # Residual + normalization\n",
    "        x = self.norm(x + update)\n",
    "\n",
    "        return x\n",
    "\n",
    "class EGNNEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features=7, hidden=hidden, layers=3, emb_dim=8):\n",
    "        super().__init__()\n",
    "\n",
    "        # üî• Critical fix: input projection\n",
    "        self.input_proj = nn.Linear(in_features, hidden)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            EGNNLayer(hidden)\n",
    "            for _ in range(layers)\n",
    "        ])\n",
    "\n",
    "        self.lin = nn.Linear(hidden, emb_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        x, pos, edge_index = data.x, data.pos, data.edge_index\n",
    "        batch = data.batch\n",
    "\n",
    "        # Project to hidden space first\n",
    "        x = self.input_proj(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, pos, edge_index)\n",
    "\n",
    "        # Graph-level invariant pooling\n",
    "        graph_embedding = global_mean_pool(x, batch)\n",
    "\n",
    "        z = self.lin(graph_embedding)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b14fa5c9-6e28-4f07-b381-e762ab4c76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGNNLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, dropout=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + 1, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "\n",
    "        row, col = edge_index\n",
    "\n",
    "        # Rotation-invariant squared distance\n",
    "        rel_pos = pos[row] - pos[col]\n",
    "        dist2 = torch.sum(rel_pos ** 2, dim=1, keepdim=True)\n",
    "\n",
    "        # Edge message\n",
    "        edge_input = torch.cat([x[row], x[col], dist2], dim=1)\n",
    "        edge_feat = self.edge_mlp(edge_input)\n",
    "\n",
    "        # Aggregate messages\n",
    "        agg = torch.zeros(\n",
    "            x.size(0),\n",
    "            x.size(1),\n",
    "            device=x.device\n",
    "        )\n",
    "        agg.index_add_(0, row, edge_feat)\n",
    "\n",
    "        # Node update\n",
    "        update = self.node_mlp(torch.cat([x, agg], dim=1))\n",
    "        update = self.dropout(update)\n",
    "\n",
    "        # Residual + normalization\n",
    "        x = self.norm(x + update)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class EGNNEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features=6, hidden=hidden, layers=3, emb_dim=20, dropout=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input projection\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden),\n",
    "            nn.LayerNorm(hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            EGNNLayer(hidden, dropout=dropout)\n",
    "            for _ in range(layers)\n",
    "        ])\n",
    "\n",
    "        self.lin = nn.Linear(hidden, emb_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        x, pos, edge_index = data.x, data.pos, data.edge_index\n",
    "        batch = data.batch\n",
    "\n",
    "        # Project to hidden space\n",
    "        x = self.input_proj(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, pos, edge_index)\n",
    "\n",
    "        # Invariant graph pooling\n",
    "        graph_embedding = global_mean_pool(x, batch)\n",
    "\n",
    "        z = self.lin(graph_embedding)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06bc864c-8da1-4092-8e35-3c8e321016f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "model = EGNNEncoder(in_features=6).to(device)\n",
    "\n",
    "single_batch = Batch.from_data_list([graph_list[0]]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_emb = model(single_batch)\n",
    "\n",
    "print(test_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a90c9d28-b263-4a98-83b3-1c5cc8bba264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(loader))\n",
    "# print(batch)\n",
    "# print(batch.x.shape)\n",
    "# print(batch.batch.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e9661b5-b8b1-4f13-83b9-17da696c9eb6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def nt_xent_loss(z, tau=0.05):\n",
    "    \"\"\"\n",
    "    NT-Xent loss for contrastive learning.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : Tensor (2N, d)\n",
    "        Normalized embeddings\n",
    "    tau : float\n",
    "        Temperature parameter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    loss : scalar tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    N = z.size(0) // 2  # number of original graphs\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 1. Normalize embeddings\n",
    "    # ----------------------------------\n",
    "    z = F.normalize(z, dim=1)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 2. Similarity matrix\n",
    "    # ----------------------------------\n",
    "    sim = torch.matmul(z, z.T) / tau  # (2N, 2N)\n",
    "\n",
    "    # Remove self-similarity\n",
    "    mask = torch.eye(2*N, device=z.device).bool()\n",
    "    sim.masked_fill_(mask, -1e9)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 3. Positive pairs\n",
    "    # ----------------------------------\n",
    "    positives = torch.cat([\n",
    "        torch.diag(sim, N),   # i -> j\n",
    "        torch.diag(sim, -N)   # j -> i\n",
    "    ])\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 4. Denominator (all negatives)\n",
    "    # ----------------------------------\n",
    "    denominator = torch.logsumexp(sim, dim=1)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # 5. Final loss\n",
    "    # ----------------------------------\n",
    "    loss = -positives + denominator\n",
    "    loss = loss.mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0248306f-55c3-4314-ad43-5810f0158608",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def supervised_contrastive_loss(z, labels, tau=0.2):\n",
    "\n",
    "    # Normalize embeddings\n",
    "    z = F.normalize(z, dim=1)\n",
    "\n",
    "    # Similarity matrix\n",
    "    sim = torch.matmul(z, z.T) / tau\n",
    "\n",
    "    N = z.size(0)\n",
    "\n",
    "    # Mask self similarity\n",
    "    self_mask = torch.eye(N, device=z.device).bool()\n",
    "    sim = sim.masked_fill(self_mask, -1e9)\n",
    "\n",
    "    labels = labels.view(-1, 1)\n",
    "\n",
    "    # Full halo positive mask\n",
    "    positive_mask = (labels == labels.T)\n",
    "    positive_mask = positive_mask & (~self_mask)\n",
    "\n",
    "    # Log-softmax\n",
    "    log_prob = sim - torch.logsumexp(sim, dim=1, keepdim=True)\n",
    "\n",
    "    # Count positives\n",
    "    pos_count = positive_mask.sum(dim=1)\n",
    "\n",
    "    # Remove anchors with zero positives (should not happen)\n",
    "    valid = pos_count > 0\n",
    "\n",
    "    loss = - (positive_mask * log_prob).sum(dim=1)[valid] / pos_count[valid]\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def halo_compactness_loss(z, labels):\n",
    "\n",
    "    z = F.normalize(z, dim=1)\n",
    "\n",
    "    unique_labels = labels.unique()\n",
    "\n",
    "    compactness = 0.0\n",
    "\n",
    "    for h in unique_labels:\n",
    "        mask = labels == h\n",
    "        z_h = z[mask]\n",
    "\n",
    "        if z_h.size(0) > 1:\n",
    "            centroid = z_h.mean(dim=0, keepdim=True)\n",
    "            compactness += ((z_h - centroid) ** 2).sum(dim=1).mean()\n",
    "\n",
    "    return compactness / len(unique_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e9c65ff-e95a-434d-8655-95aec0bbf9ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def halo_contrastive_compact_loss(z, labels, tau=0.2, lambda_compact=0.5):\n",
    "    \"\"\"\n",
    "    Physics-aware halo representation loss.\n",
    "\n",
    "    Components:\n",
    "    1) Supervised contrastive separation (push halos apart)\n",
    "    2) Halo compactness penalty (shrink intra-halo scatter)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : tensor (N, d)\n",
    "        Graph embeddings\n",
    "    labels : tensor (N,)\n",
    "        Halo labels\n",
    "    tau : float\n",
    "        Temperature\n",
    "    lambda_compact : float\n",
    "        Weight for compactness term\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # Normalize embeddings\n",
    "    # -----------------------------\n",
    "    z = F.normalize(z, dim=1)\n",
    "\n",
    "    N = z.size(0)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Supervised Contrastive Term\n",
    "    # -----------------------------\n",
    "    sim = torch.matmul(z, z.T) / tau\n",
    "\n",
    "    self_mask = torch.eye(N, device=z.device).bool()\n",
    "    sim = sim.masked_fill(self_mask, -1e9)\n",
    "\n",
    "    labels = labels.view(-1, 1)\n",
    "\n",
    "    positive_mask = (labels == labels.T) & (~self_mask)\n",
    "\n",
    "    log_prob = sim - torch.logsumexp(sim, dim=1, keepdim=True)\n",
    "\n",
    "    pos_count = positive_mask.sum(dim=1)\n",
    "    valid = pos_count > 0\n",
    "\n",
    "    contrastive_loss = - (\n",
    "        (positive_mask * log_prob).sum(dim=1)[valid] / pos_count[valid]\n",
    "    ).mean()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Halo Compactness Term\n",
    "    # -----------------------------\n",
    "    unique_labels = labels.unique()\n",
    "\n",
    "    intra_scatter = 0.0\n",
    "    for h in unique_labels:\n",
    "        mask = (labels.squeeze() == h.squeeze())\n",
    "        z_h = z[mask]\n",
    "\n",
    "        if z_h.size(0) > 1:\n",
    "            centroid = z_h.mean(dim=0, keepdim=True)\n",
    "            intra_scatter += ((z_h - centroid) ** 2).sum(dim=1).mean()\n",
    "\n",
    "    compactness_loss = intra_scatter / len(unique_labels)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Total Loss\n",
    "    # -----------------------------\n",
    "    total_loss = contrastive_loss + lambda_compact * compactness_loss\n",
    "\n",
    "    return total_loss, contrastive_loss.detach(), compactness_loss.detach()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1705acfa-738f-4a97-872a-5133bf05ebf6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def generate_time_contrastive_batch(\n",
    "    stream_metadata,\n",
    "    k=k,\n",
    "    device=\"cpu\",\n",
    "    time_samples_per_stream=3,   # <-- critical control\n",
    "    \n",
    "):\n",
    "    \"\"\"\n",
    "    Build batch dynamically each epoch.\n",
    "\n",
    "    For each stream:\n",
    "        - Randomly sample multiple time indices\n",
    "        - Build graph\n",
    "    Batch contains:\n",
    "        3 streams √ó time_samples √ó 3 halos\n",
    "    \"\"\"\n",
    "\n",
    "    graphs = []\n",
    "\n",
    "    for meta in stream_metadata:\n",
    "\n",
    "        stream = meta[\"stream_object\"]\n",
    "        time_array = meta[\"time_array\"]\n",
    "        halo_id = meta[\"halo_id\"]\n",
    "\n",
    "        total_time_steps = len(time_array)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Randomly sample times\n",
    "        # -----------------------------\n",
    "        time_indices = np.random.choice(\n",
    "            total_time_steps,\n",
    "            size=time_samples_per_stream,\n",
    "            replace=False\n",
    "        )\n",
    "\n",
    "        for t_idx in time_indices:\n",
    "\n",
    "            snapshot = extract_stream_snapshot(\n",
    "                stream,\n",
    "                time_array,\n",
    "                time_index=int(t_idx)\n",
    "            )\n",
    "\n",
    "            graph = build_stream_graph(\n",
    "                snapshot,\n",
    "                halo_id=halo_id,\n",
    "                k=k,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            graphs.append(graph)\n",
    "\n",
    "    # Unified batch\n",
    "    batch = Batch.from_data_list(graphs).to(device)\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "def build_evaluation_graphs(\n",
    "    stream_metadata,\n",
    "    n_eval_times=4,\n",
    "    k=k,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "\n",
    "    evaluation_graphs = []\n",
    "\n",
    "    for meta in stream_metadata:\n",
    "\n",
    "        stream = meta[\"stream_object\"]\n",
    "        time_array = meta[\"time_array\"]\n",
    "        halo_id = meta[\"halo_id\"]\n",
    "\n",
    "        total_steps = len(time_array)\n",
    "\n",
    "        # -----------------------------------\n",
    "        # FIXED, deterministic time sampling\n",
    "        # -----------------------------------\n",
    "        eval_indices = np.linspace(\n",
    "            0,\n",
    "            total_steps - 1,\n",
    "            n_eval_times\n",
    "        ).astype(int)\n",
    "\n",
    "        for t_idx in eval_indices:\n",
    "\n",
    "            snapshot = extract_stream_snapshot(\n",
    "                stream,\n",
    "                time_array,\n",
    "                time_index=int(t_idx)\n",
    "            )\n",
    "\n",
    "            graph = build_stream_graph(\n",
    "                snapshot,\n",
    "                halo_id=halo_id,\n",
    "                k=k,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            graph.time_index = torch.tensor(t_idx, device=device)\n",
    "\n",
    "            evaluation_graphs.append(graph)\n",
    "\n",
    "    return evaluation_graphs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19059ed6-4cac-4ed0-a172-4f528d24e6aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def inspect_positive_counts(labels):\n",
    "\n",
    "        labels = labels.view(-1, 1)\n",
    "        mask = torch.eye(labels.size(0), device=labels.device).bool()\n",
    "    \n",
    "        positive_mask = (labels == labels.T)\n",
    "        positive_mask = positive_mask & (~mask)\n",
    "    \n",
    "        pos_counts = positive_mask.sum(dim=1)\n",
    "    \n",
    "        print(\"Positive counts per anchor:\", pos_counts.cpu().numpy())\n",
    "        print(\"Min positives:\", pos_counts.min().item())\n",
    "        print(\"Max positives:\", pos_counts.max().item())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ba4cf9c-38ba-4952-a626-80d643296bd8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# def generate_contrastive_batch(graph_list, device, k=k, keep_ratio=0.9):\n",
    "\n",
    "#     augmented_graphs = []\n",
    "\n",
    "#     for graph in graph_list:\n",
    "#         g1, g2 = generate_contrastive_pair(graph, k=k, keep_ratio=keep_ratio)\n",
    "#         augmented_graphs.extend([g1, g2])\n",
    "\n",
    "#     batch = Batch.from_data_list(augmented_graphs).to(device)\n",
    "\n",
    "#     return batch\n",
    "\n",
    "# def generate_contrastive_batch(stream_metadata, k=16):\n",
    "\n",
    "#     augmented_graphs = []\n",
    "\n",
    "#     for meta in stream_metadata:\n",
    "\n",
    "#         total_time_steps = len(meta[\"time_array\"])\n",
    "\n",
    "#         # Random time index each epoch\n",
    "#         t_idx = np.random.randint(0, total_time_steps)\n",
    "\n",
    "#         stream_snapshot = extract_stream_snapshot(\n",
    "#             meta[\"stream\"],\n",
    "#             meta[\"time_array\"],\n",
    "#             time_index=t_idx\n",
    "#         )\n",
    "\n",
    "#         base_graph = build_stream_graph(\n",
    "#             stream_snapshot,\n",
    "#             halo_id=meta[\"halo_id\"],\n",
    "#             k=k\n",
    "#         )\n",
    "\n",
    "#         # Two augmentations\n",
    "#         g1 = augment_graph(base_graph, k=k)\n",
    "#         g2 = augment_graph(base_graph, k=k)\n",
    "\n",
    "#         augmented_graphs.append(g1)\n",
    "#         augmented_graphs.append(g2)\n",
    "\n",
    "#     loader = DataLoader(\n",
    "#         augmented_graphs,\n",
    "#         batch_size=len(augmented_graphs),\n",
    "#         shuffle=False\n",
    "#     )\n",
    "\n",
    "#     return next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4487ad18-e6e8-4b15-b901-ceadbc6feab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_contrastive_loss(z, labels, tau=0.2):\n",
    "    \"\"\"\n",
    "    Standard Supervised Contrastive Loss\n",
    "    (Khosla et al., 2020)\n",
    "\n",
    "    Encourages embeddings of streams from the same halo\n",
    "    to cluster, while separating different halos.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : (N, d)\n",
    "        Graph embeddings\n",
    "    labels : (N,)\n",
    "        Halo labels\n",
    "    tau : float\n",
    "        Temperature\n",
    "    \"\"\"\n",
    "\n",
    "    z = F.normalize(z, dim=1)\n",
    "    N = z.size(0)\n",
    "\n",
    "    sim = torch.matmul(z, z.T) / tau\n",
    "\n",
    "    # Remove self-similarity\n",
    "    self_mask = torch.eye(N, device=z.device).bool()\n",
    "    sim = sim.masked_fill(self_mask, -1e9)\n",
    "\n",
    "    labels = labels.view(-1, 1)\n",
    "    positive_mask = (labels == labels.T) & (~self_mask)\n",
    "\n",
    "    log_prob = sim - torch.logsumexp(sim, dim=1, keepdim=True)\n",
    "\n",
    "    pos_count = positive_mask.sum(dim=1)\n",
    "    valid = pos_count > 0\n",
    "\n",
    "    loss = - (positive_mask * log_prob).sum(dim=1)[valid] / pos_count[valid]\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def generate_time_contrastive_batch(\n",
    "    stream_metadata,\n",
    "    k=k,\n",
    "    device=\"cpu\",\n",
    "    time_samples_per_stream=4\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a shuffled batch dynamically each epoch.\n",
    "\n",
    "    - Shuffles stream order\n",
    "    - Randomly samples time steps\n",
    "    - Shuffles final graph list before batching\n",
    "    \"\"\"\n",
    "\n",
    "    graphs = []\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 1Ô∏è‚É£ Shuffle stream order\n",
    "    # -----------------------------------------\n",
    "    shuffled_streams = np.random.permutation(stream_metadata)\n",
    "\n",
    "    for meta in shuffled_streams:\n",
    "\n",
    "        stream = meta[\"stream_object\"]\n",
    "        time_array = meta[\"time_array\"]\n",
    "        halo_id = meta[\"halo_id\"]\n",
    "\n",
    "        total_time_steps = len(time_array)\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # 2Ô∏è‚É£ Random time sampling\n",
    "        # -----------------------------------------\n",
    "        time_indices = np.random.choice(\n",
    "            total_time_steps,\n",
    "            size=time_samples_per_stream,\n",
    "            replace=False\n",
    "        )\n",
    "\n",
    "        for t_idx in time_indices:\n",
    "\n",
    "            snapshot = extract_stream_snapshot(\n",
    "                stream,\n",
    "                time_array,\n",
    "                time_index=int(t_idx)\n",
    "            )\n",
    "\n",
    "            graph = build_stream_graph(\n",
    "                snapshot,\n",
    "                halo_id=halo_id,\n",
    "                k=k,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            graphs.append(graph)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 3Ô∏è‚É£ Shuffle graph order\n",
    "    # -----------------------------------------\n",
    "    np.random.shuffle(graphs)\n",
    "\n",
    "    batch = Batch.from_data_list(graphs).to(device)\n",
    "\n",
    "    return batch\n",
    "\n",
    "def build_evaluation_graphs(\n",
    "    stream_metadata,\n",
    "    n_eval_times=4,\n",
    "    k=8,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Deterministic evaluation set.\n",
    "    No augmentation.\n",
    "    Fixed time slices.\n",
    "    \"\"\"\n",
    "\n",
    "    evaluation_graphs = []\n",
    "\n",
    "    for meta in stream_metadata:\n",
    "\n",
    "        stream = meta[\"stream_object\"]\n",
    "        time_array = meta[\"time_array\"]\n",
    "        halo_id = meta[\"halo_id\"]\n",
    "\n",
    "        total_steps = len(time_array)\n",
    "\n",
    "        eval_indices = np.linspace(\n",
    "            0,\n",
    "            total_steps - 1,\n",
    "            n_eval_times\n",
    "        ).astype(int)\n",
    "\n",
    "        for t_idx in eval_indices:\n",
    "\n",
    "            snapshot = extract_stream_snapshot(\n",
    "                stream,\n",
    "                time_array,\n",
    "                time_index=int(t_idx)\n",
    "            )\n",
    "\n",
    "            graph = build_stream_graph(\n",
    "                snapshot,\n",
    "                halo_id=halo_id,\n",
    "                k=k,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            evaluation_graphs.append(graph)\n",
    "\n",
    "    return evaluation_graphs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "861bd224-4af8-4bee-a1e1-5a4e903c6560",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def halo_prototype_loss(\n",
    "    z,\n",
    "    labels,\n",
    "    temperature=0.08,\n",
    "    margin=0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Angular prototype loss (ArcFace-style margin).\n",
    "\n",
    "    Physically:\n",
    "    - Each halo = deformation prototype\n",
    "    - Intra-halo scatter minimized\n",
    "    - Inter-halo angular separation enforced\n",
    "\n",
    "    References:\n",
    "    - Prototypical Networks (Snell et al., 2017)\n",
    "    - ArcFace (Deng et al., 2019)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Normalize embeddings\n",
    "    # ---------------------------------\n",
    "    z = F.normalize(z, dim=1)\n",
    "\n",
    "    unique_labels = torch.unique(labels)\n",
    "    centroids = []\n",
    "\n",
    "    for h in unique_labels:\n",
    "        mask = labels == h\n",
    "        centroids.append(z[mask].mean(dim=0))\n",
    "\n",
    "    centroids = torch.stack(centroids)\n",
    "    centroids = F.normalize(centroids, dim=1)\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Cosine similarity\n",
    "    # ---------------------------------\n",
    "    cosine = torch.matmul(z, centroids.T)\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Apply angular margin\n",
    "    # ---------------------------------\n",
    "    label_map = {int(h.item()): i for i, h in enumerate(unique_labels)}\n",
    "    target = torch.tensor(\n",
    "        [label_map[int(l.item())] for l in labels],\n",
    "        device=z.device\n",
    "    )\n",
    "\n",
    "    one_hot = F.one_hot(target, num_classes=len(unique_labels)).float()\n",
    "\n",
    "    # subtract margin from correct class cosine\n",
    "    cosine_margin = cosine - one_hot * margin\n",
    "\n",
    "    logits = cosine_margin / temperature\n",
    "\n",
    "    loss = F.cross_entropy(logits, target)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c17455f-8664-4011-aa3f-5a7a90de8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halo_prototype_loss(z, labels, temperature=0.07):\n",
    "    \"\"\"\n",
    "    Simple, stable halo clustering loss.\n",
    "\n",
    "    Steps:\n",
    "    1. Normalize embeddings\n",
    "    2. Compute halo centroids\n",
    "    3. Classify each embedding via distance to centroids\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize\n",
    "    z = F.normalize(z, dim=1)\n",
    "\n",
    "    unique_labels = labels.unique()\n",
    "    centroids = []\n",
    "\n",
    "    for h in unique_labels:\n",
    "        mask = labels == h\n",
    "        centroids.append(z[mask].mean(dim=0))\n",
    "\n",
    "    centroids = torch.stack(centroids)  # (H, d)\n",
    "    centroids = F.normalize(centroids, dim=1)\n",
    "\n",
    "    # Compute cosine similarity to centroids\n",
    "    logits = torch.matmul(z, centroids.T) / temperature\n",
    "\n",
    "    # Map labels to 0..H-1 index\n",
    "    label_map = {int(h.item()): i for i, h in enumerate(unique_labels)}\n",
    "    target = torch.tensor(\n",
    "        [label_map[int(l.item())] for l in labels],\n",
    "        device=z.device\n",
    "    )\n",
    "\n",
    "    loss = F.cross_entropy(logits, target)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e231bed0-4063-4953-a6b9-aaf7c5d09835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_positive_supervised_contrastive_loss(\n",
    "    z,\n",
    "    halo_labels,\n",
    "    tau=0.12\n",
    "):\n",
    "    \"\"\"\n",
    "    Multi-positive supervised contrastive loss\n",
    "    (Khosla et al., 2020)\n",
    "\n",
    "    Positives:\n",
    "        - All samples belonging to same halo\n",
    "        - Includes same stream across time automatically\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : Tensor (N, d)\n",
    "        Graph embeddings\n",
    "    halo_labels : Tensor (N,)\n",
    "        Halo ID for each graph\n",
    "    tau : float\n",
    "        Temperature parameter\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : scalar Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Normalize embeddings (critical)\n",
    "    # ----------------------------------------\n",
    "    z = F.normalize(z, dim=1)\n",
    "\n",
    "    N = z.size(0)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Similarity matrix\n",
    "    # ----------------------------------------\n",
    "    sim = torch.matmul(z, z.T) / tau\n",
    "\n",
    "    # Mask self-similarity\n",
    "    self_mask = torch.eye(N, device=z.device).bool()\n",
    "    sim = sim.masked_fill(self_mask, -1e9)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Build positive mask (same halo)\n",
    "    # ----------------------------------------\n",
    "    halo_labels = halo_labels.view(-1, 1)\n",
    "\n",
    "    positive_mask = (halo_labels == halo_labels.T)\n",
    "    positive_mask = positive_mask & (~self_mask)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Log-softmax denominator\n",
    "    # ----------------------------------------\n",
    "    log_prob = sim - torch.logsumexp(sim, dim=1, keepdim=True)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Count positives per anchor\n",
    "    # ----------------------------------------\n",
    "    pos_count = positive_mask.sum(dim=1)\n",
    "\n",
    "    # Remove anchors without positives (should not happen)\n",
    "    valid = pos_count > 0\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Final loss\n",
    "    # ----------------------------------------\n",
    "    loss = -(\n",
    "        (positive_mask * log_prob).sum(dim=1)[valid]\n",
    "        / pos_count[valid]\n",
    "    ).mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd094865-5498-4001-b3db-5ee90e9df511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 76948\n",
      "CUDA: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vasu/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation graphs: 54\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1807d2bab0744696b6c0324d9bde9a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "Loss: 1.0945\n",
      "Best Loss: 1.0945 (epoch 0)\n",
      "Silhouette (clean eval): 0.0191\n",
      "Embedding norm: 1.0000\n",
      "Elapsed: 6.5s | ETA: 3242.3s\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 10\n",
      "Loss: 1.0258\n",
      "Best Loss: 0.8366 (epoch 7)\n",
      "Silhouette (clean eval): 0.0964\n",
      "Embedding norm: 1.0000\n",
      "Elapsed: 61.2s | ETA: 2719.8s\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 20\n",
      "Loss: 0.7028\n",
      "Best Loss: 0.6967 (epoch 19)\n",
      "Silhouette (clean eval): 0.1768\n",
      "Embedding norm: 1.0000\n",
      "Elapsed: 115.8s | ETA: 2642.4s\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 30\n",
      "Loss: 1.0206\n",
      "Best Loss: 0.6536 (epoch 25)\n",
      "Silhouette (clean eval): 0.2011\n",
      "Embedding norm: 1.0000\n",
      "Elapsed: 169.6s | ETA: 2565.9s\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 40\n",
      "Loss: 0.6748\n",
      "Best Loss: 0.6180 (epoch 37)\n",
      "Silhouette (clean eval): 0.2044\n",
      "Embedding norm: 1.0000\n",
      "Elapsed: 223.5s | ETA: 2501.9s\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 50\n",
      "Loss: 0.7278\n",
      "Best Loss: 0.6180 (epoch 37)\n",
      "Silhouette (clean eval): 0.2202\n",
      "Embedding norm: 1.0000\n",
      "Elapsed: 276.2s | ETA: 2432.0s\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 60\n",
      "Loss: 0.5756\n",
      "Best Loss: 0.5756 (epoch 60)\n",
      "Silhouette (clean eval): 0.1917\n",
      "Embedding norm: 1.0000\n",
      "Elapsed: 325.2s | ETA: 2340.5s\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 70\n",
      "Loss: 0.8479\n",
      "Best Loss: 0.5249 (epoch 61)\n",
      "Silhouette (clean eval): 0.1554\n",
      "Embedding norm: 1.0000\n",
      "Elapsed: 371.3s | ETA: 2243.2s\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 80\n",
      "Loss: 0.9609\n",
      "Best Loss: 0.5249 (epoch 61)\n",
      "Silhouette (clean eval): 0.1717\n",
      "Embedding norm: 1.0000\n",
      "Elapsed: 427.7s | ETA: 2212.4s\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Model\n",
    "# ---------------------------------------------\n",
    "model = EGNNEncoder(\n",
    "    in_features=6,\n",
    "    hidden=hidden,\n",
    "    layers=3,\n",
    "    emb_dim=20\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))\n",
    "print(\"CUDA:\", next(model.parameters()).is_cuda)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Evaluation graphs (clean)\n",
    "# ---------------------------------------------\n",
    "evaluation_graph_list = build_evaluation_graphs(\n",
    "    stream_metadata,\n",
    "    n_eval_times=n_time_samples,\n",
    "    k=k,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Evaluation graphs:\", len(evaluation_graph_list))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Training hyperparameters\n",
    "# ---------------------------------------------\n",
    "epochs = 500\n",
    "tau = 0.1\n",
    "#lambda_compact = 0.3\n",
    "\n",
    "min_epochs = 100\n",
    "patience = 30\n",
    "improve_threshold = 3e-4\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "best_epoch = 0\n",
    "no_improve_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# TRAIN LOOP\n",
    "# ---------------------------------------------\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # ==============================\n",
    "    # TRAIN\n",
    "    # ==============================\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch = generate_time_contrastive_batch(\n",
    "        stream_metadata,\n",
    "        k=k,\n",
    "        device=device,\n",
    "        time_samples_per_stream=4\n",
    "    )\n",
    "\n",
    "    labels = batch.halo_id.view(-1)\n",
    "\n",
    "    z = model(batch)\n",
    "\n",
    "    #loss = supervised_contrastive_loss(z, labels, tau=tau)\n",
    "    \n",
    "    loss = halo_prototype_loss(z, labels, temperature=0.1,) #margin=0.2)\n",
    "    \n",
    "    # loss = multi_positive_supervised_contrastive_loss(\n",
    "    #     z,\n",
    "    #     labels,\n",
    "    #     tau=tau\n",
    "    # )\n",
    "    \n",
    "    # loss_comp = halo_compactness_loss(z, labels)\n",
    "\n",
    "    # loss = loss_sc + 0.5 * loss_comp\n",
    "\n",
    "    # loss_tuple = halo_contrastive_compact_loss(z, labels, tau=tau, lambda_compact=lambda_compact)\n",
    "    # loss = loss_tuple[0]\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_val = loss.item()\n",
    "    loss_history.append(loss_val)\n",
    "\n",
    "    scheduler.step(loss_val)\n",
    "\n",
    "    # ==============================\n",
    "    # SAVE BEST MODEL\n",
    "    # ==============================\n",
    "    if loss_val < best_loss - improve_threshold:\n",
    "        best_loss = loss_val\n",
    "        best_epoch = epoch\n",
    "        no_improve_counter = 0\n",
    "\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_state, \"best_egnn_model.pt\")\n",
    "\n",
    "    else:\n",
    "        no_improve_counter += 1\n",
    "\n",
    "    # ==============================\n",
    "    # EARLY STOPPING\n",
    "    # ==============================\n",
    "    if epoch > min_epochs and no_improve_counter >= patience:\n",
    "        print(f\"\\nStopping early at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "    # ==============================\n",
    "    # MONITORING\n",
    "    # ==============================\n",
    "    if epoch % 10 == 0:\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            eval_batch = Batch.from_data_list(\n",
    "                evaluation_graph_list\n",
    "            ).to(device)\n",
    "\n",
    "            z_eval = model(eval_batch)\n",
    "            z_eval = torch.nn.functional.normalize(z_eval, dim=1)\n",
    "\n",
    "            z_np = z_eval.cpu().numpy()\n",
    "            labels_np = eval_batch.halo_id.view(-1).cpu().numpy()\n",
    "\n",
    "            sil_score = silhouette_score(z_np, labels_np)\n",
    "            embedding_norm = torch.norm(z_eval, dim=1).mean().item()\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = (epoch + 1) / epochs\n",
    "        eta = elapsed * (1 - progress) / max(progress, 1e-8)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}\")\n",
    "        print(f\"Loss: {loss_val:.4f}\")\n",
    "        print(f\"Best Loss: {best_loss:.4f} (epoch {best_epoch})\")\n",
    "        print(f\"Silhouette (clean eval): {sil_score:.4f}\")\n",
    "        print(f\"Embedding norm: {embedding_norm:.4f}\")\n",
    "        print(f\"Elapsed: {elapsed:.1f}s | ETA: {eta:.1f}s\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# LOAD BEST MODEL AFTER TRAINING\n",
    "# ---------------------------------------------\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"\\nLoaded best model from epoch {best_epoch}\")\n",
    "else:\n",
    "    print(\"\\nNo improvement detected during training.\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "print(f\"Best Loss: {best_loss:.4f}\")\n",
    "print(f\"Total time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc8b8fc-cabc-4b80-9c22-c6cc69d78b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ca4251cb-f774-43d9-b370-af1cfa0eac76",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# --------------------------------------------------\n",
    "# Model & Optimizer\n",
    "# --------------------------------------------------\n",
    "model = EGNNEncoder(\n",
    "    in_features=7,\n",
    "    hidden=hidden,\n",
    "    layers=3,\n",
    "    emb_dim=8\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))\n",
    "print(\"On CUDA:\", next(model.parameters()).is_cuda)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Build clean evaluation graphs (NO augmentation)\n",
    "# --------------------------------------------------\n",
    "evaluation_graph_list = build_evaluation_graphs(\n",
    "    stream_metadata,\n",
    "    n_eval_times=6,\n",
    "    k=k,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Evaluation graphs:\", len(evaluation_graph_list))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Training Hyperparameters\n",
    "# --------------------------------------------------\n",
    "epochs = 400\n",
    "tau = 0.07\n",
    "\n",
    "patience = 120\n",
    "min_epochs = 80\n",
    "improve_threshold = 1e-3\n",
    "\n",
    "best_silhouette = -1.0\n",
    "no_improve_counter = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "\n",
    "# ==================================================\n",
    "# TRAINING LOOP\n",
    "# ==================================================\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # ===============================\n",
    "    # Train\n",
    "    # ===============================\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch = generate_time_contrastive_batch(\n",
    "        stream_metadata,\n",
    "        k=k,\n",
    "        device=device,\n",
    "        time_samples_per_stream=4\n",
    "    )\n",
    "\n",
    "    labels = batch.halo_id.view(-1)\n",
    "\n",
    "    z = model(batch)\n",
    "    loss = supervised_contrastive_loss(z, labels, tau=tau)\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    # ===============================\n",
    "    # Evaluation (every 10 epochs)\n",
    "    # ===============================\n",
    "    if epoch % 10 == 0:\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            eval_batch = Batch.from_data_list(\n",
    "                evaluation_graph_list\n",
    "            ).to(device)\n",
    "\n",
    "            z_eval = model(eval_batch)\n",
    "            z_eval = F.normalize(z_eval, dim=1)\n",
    "\n",
    "            z_np = z_eval.cpu().numpy()\n",
    "            labels_np = eval_batch.halo_id.view(-1).cpu().numpy()\n",
    "\n",
    "            sil_score = silhouette_score(z_np, labels_np)\n",
    "            embedding_norm = torch.norm(z_eval, dim=1).mean().item()\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = (epoch + 1) / epochs\n",
    "        eta = elapsed * (1 - progress) / max(progress, 1e-8)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}\")\n",
    "        print(f\"Loss: {loss.item():.4f}\")\n",
    "        print(f\"Silhouette (clean eval): {sil_score:.4f}\")\n",
    "        print(f\"Embedding norm: {embedding_norm:.4f}\")\n",
    "        print(f\"Elapsed: {elapsed:.1f}s | ETA: {eta:.1f}s\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # ==========================================\n",
    "        # Early Stopping (based on silhouette)\n",
    "        # ==========================================\n",
    "        if sil_score > best_silhouette + improve_threshold:\n",
    "            best_silhouette = sil_score\n",
    "            no_improve_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        else:\n",
    "            no_improve_counter += 1\n",
    "\n",
    "        if epoch > min_epochs and no_improve_counter > patience:\n",
    "            print(f\"\\nStopping early at epoch {epoch} (silhouette plateau)\")\n",
    "            break\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load Best Model\n",
    "# --------------------------------------------------\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "print(f\"Best silhouette: {best_silhouette:.4f}\")\n",
    "print(f\"Total time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82736eff-f286-4dd3-9446-30c9e090d4f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "model.eval()\n",
    "batch = generate_time_contrastive_batch(\n",
    "        stream_metadata,\n",
    "        k=k,\n",
    "        device=device,\n",
    "        time_samples_per_stream=6\n",
    "    )\n",
    "batch = batch.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = model(batch).cpu().numpy()\n",
    "\n",
    "labels = batch.halo_id.cpu().numpy()\n",
    "\n",
    "clf = LogisticRegression().fit(z, labels)\n",
    "preds = clf.predict(z)\n",
    "\n",
    "acc = accuracy_score(labels, preds)\n",
    "\n",
    "print(\"Linear probe accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b603b0-1323-4551-969a-61ca92a21a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_all = Batch.from_data_list(graph_list).to(device)\n",
    "    embeddings = model(batch_all)\n",
    "\n",
    "embeddings_np = embeddings.cpu().numpy()\n",
    "embeddings_np = embeddings_np / np.linalg.norm(embeddings_np, axis=1, keepdims=True)\n",
    "\n",
    "# Correct labels\n",
    "labels = batch_all.halo_id.view(-1).cpu().numpy()\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings_np.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c1874-8707-4891-bc7a-22a4305130a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings_np, labels)):\n",
    "\n",
    "    X_train = embeddings_np[train_idx]\n",
    "    y_train = labels_np[train_idx]\n",
    "\n",
    "    X_test = embeddings_np[test_idx]\n",
    "    y_test = labels_np[test_idx]\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=2000,\n",
    "         C=0.5,\n",
    "        solver=\"lbfgs\",\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    # Store for confusion matrix\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nMean Accuracy:\", np.mean(accuracies))\n",
    "print(\"Std Accuracy :\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede0b73-15f2-4798-8095-49fe6bf4264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_y_true, all_y_pred)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Spherical\", \"Oblate\", \"Prolate\"],\n",
    "    yticklabels=[\"Spherical\", \"Oblate\", \"Prolate\"]\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Linear Probe Confusion Matrix (5-fold CV)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a00c73-6d1c-46c5-aa54-1f8e4a2adfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16206d0e-6eb2-4f14-b8f8-bad63320e2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "emb_2d = pca.fit_transform(embeddings_np)\n",
    "\n",
    "explained = pca.explained_variance_ratio_\n",
    "\n",
    "halo_names = {\n",
    "    0: \"Spherical\",\n",
    "    1: \"Oblate\",\n",
    "    2: \"Prolate\"\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    0: \"#1f77b4\",\n",
    "    1: \"#d62728\",\n",
    "    2: \"#2ca02c\"\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "\n",
    "for halo_id in np.unique(labels):\n",
    "\n",
    "    mask = labels == halo_id\n",
    "\n",
    "    plt.scatter(\n",
    "        emb_2d[mask, 0],\n",
    "        emb_2d[mask, 1],\n",
    "        s=120,\n",
    "        label=halo_names[halo_id],\n",
    "        color=colors[halo_id],\n",
    "        edgecolor=\"k\",\n",
    "        alpha=0.85\n",
    "    )\n",
    "\n",
    "    centroid = emb_2d[mask].mean(axis=0)\n",
    "\n",
    "    plt.scatter(\n",
    "        centroid[0],\n",
    "        centroid[1],\n",
    "        s=250,\n",
    "        marker=\"X\",\n",
    "        color=colors[halo_id],\n",
    "        edgecolor=\"black\"\n",
    "    )\n",
    "\n",
    "plt.xlabel(f\"PC1 ({explained[0]*100:.1f}% var)\")\n",
    "plt.ylabel(f\"PC2 ({explained[1]*100:.1f}% var)\")\n",
    "plt.title(\"Stream Embeddings (Contrastive EGNN)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2521a02-a048-4035-9a38-0a2583e43869",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(emb_2d[mask, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c421c0a-ec1a-4e2a-b3b6-c4990a0dcd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_halo_distance_ratio(model, evaluation_graph_list, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch = Batch.from_data_list(evaluation_graph_list).to(device)\n",
    "        z = model(batch)\n",
    "        z = F.normalize(z, dim=1)\n",
    "\n",
    "    embeddings = z.cpu().numpy()\n",
    "    labels = batch.halo_id.view(-1).cpu().numpy()\n",
    "\n",
    "    # Pairwise Euclidean distances\n",
    "    D = pairwise_distances(embeddings, metric=\"euclidean\")\n",
    "\n",
    "    intra_distances = []\n",
    "    inter_distances = []\n",
    "\n",
    "    N = len(labels)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "\n",
    "            if labels[i] == labels[j]:\n",
    "                intra_distances.append(D[i, j])\n",
    "            else:\n",
    "                inter_distances.append(D[i, j])\n",
    "\n",
    "    intra_mean = np.mean(intra_distances)\n",
    "    inter_mean = np.mean(inter_distances)\n",
    "\n",
    "    ratio = inter_mean / (intra_mean + 1e-8)\n",
    "\n",
    "    return intra_mean, inter_mean, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606b3d4-ad37-4782-8a23-a0de3cb14bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra, inter, ratio = compute_halo_distance_ratio(\n",
    "    model,\n",
    "    evaluation_graph_list,\n",
    "    device\n",
    ")\n",
    "\n",
    "print(\"Mean intra-halo distance:\", intra)\n",
    "print(\"Mean inter-halo distance:\", inter)\n",
    "print(\"Inter/Intra ratio:\", ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91877faf-1d37-45d2-9f5e-7d0221767483",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ea57a-afa3-42fb-8ad1-3c52aa8ac0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "smoothed = np.convolve(loss_history, np.ones(window)/window, mode='valid')\n",
    "plt.plot(smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db364c-84b2-4ff5-a293-117fca7a642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "# emb_umap = reducer.fit_transform(embeddings_np)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7d13fa-1fc1-4e18-9813-f4dd96f5c648",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Fit UMAP\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=10,\n",
    "    min_dist=0.2,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "emb_2d = reducer.fit_transform(embeddings_np)\n",
    "\n",
    "halo_names = {\n",
    "    0: \"Spherical\",\n",
    "    1: \"Oblate\",\n",
    "    2: \"Prolate\"\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    0: \"#1f77b4\",\n",
    "    1: \"#d62728\",\n",
    "    2: \"#2ca02c\"\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "\n",
    "for halo_id in np.unique(labels):\n",
    "    \n",
    "    mask = labels == halo_id\n",
    "    \n",
    "    plt.scatter(\n",
    "        emb_2d[mask, 0],\n",
    "        emb_2d[mask, 1],\n",
    "        s=120,\n",
    "        label=halo_names[halo_id],\n",
    "        color=colors[halo_id],\n",
    "        edgecolor=\"k\",\n",
    "        alpha=0.85\n",
    "    )\n",
    "\n",
    "plt.title(\"UMAP Projection of Stream Embeddings\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
